{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLPTK: тулкит для Natural Language Processing\n",
    "\n",
    "## Работа с классом Text: основные методы и свойства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# минимально необходимые внешние модули\n",
    "#!pip install chardet\n",
    "#!pip install dawg\n",
    "#!pip install gensim\n",
    "#!pip install pattern\n",
    "#!pip install razdel\n",
    "#!pip install pymorphy2\n",
    "\n",
    "import sys, os\n",
    "# сменим рабочую директорию на ту, где расположен каталог с библиотекой nlptk\n",
    "os.chdir(r'D:\\INSTALL\\Python3\\PROJECTS\\REPOS\\nlp_toolkit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nlptk.mining.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим этот путь в sys.path, чтобы интерпретатор увидел нашу библиотеку\n",
    "sys.path.append(r'D:\\INSTALL\\Python3\\PROJECTS\\REPOS\\nlp_toolkit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pprint import pprint\n",
    "import nlptk\n",
    "from nlptk.mining.text import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentencizer': <function nlptk.misc.mixins.SentencizerMixin.sentencize_nltk(text, *args, lang='english', **kwargs)>,\n",
       " 'tokenizer': functools.partial(<function TokenizerMixin.toktok_tokenize at 0x118C7D20>, strip='!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'),\n",
       " 'tagger': <function nlptk.misc.mixins.TaggerMixin.tagger_nltk(tokens, *args, lang='eng', **kwargs)>,\n",
       " 'lemmatizer': functools.partial(<function LemmatizerMixin.lemmatize_nltk at 0x118C7AE0>, pos=True, normalize_uppercase=<method 'capitalize' of 'str' objects>)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создаем экземпляр класса Prep c настройками по умолчанию\n",
    "prep = Prep()\n",
    "# это то, что будет использоваться при обработке текста\n",
    "prep.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# набор правил для очистки текста; применяются на этапе работы с необработанным текстом;\n",
    "rules_clean = OrderedDict(\n",
    "        roman_numerals=(True,) # здесь еще много всяких правил используемых по умолчанию\n",
    ")\n",
    "# набор правил для фильтра токенов; применяются на этапе запроса слов\\токенов\\лемм из тэгированного текста\n",
    "# могут быть включены на уровне составления вокабуляра класса Corpus \n",
    "# (по умолчанию фильтрация выключена, поэтому вокабуляр максимально полный)\n",
    "rules_filter = OrderedDict(\n",
    "        by_tagpos=(True,{},{\"FW\",\"POS\"}), # фильтр по тегам частей речи - игнорировать иностранные слова и possessive ending parent's\n",
    "        punctuation=True, # по умолчанию\n",
    "        short=(True,3),   # по умолчанию\n",
    "        stopwords=True,   # по умолчанию\n",
    "        ifnotin_lexicon=True\n",
    "        #trailing_chars=True\n",
    ")\n",
    "\n",
    "# классы которым передаются правила, сами же экземпляры классов передаются в конструктор класса Text\n",
    "clean = TextCleaner(rules_clean)\n",
    "filters = TokenFilter(rules_filter)   \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hyphenation', (True,)),\n",
       "             ('accent', (True,)),\n",
       "             ('tags', (True,)),\n",
       "             ('urls', (True,)),\n",
       "             ('numeric', (True,)),\n",
       "             ('nonletter_sequences', (True,)),\n",
       "             ('quotes', (True,)),\n",
       "             ('multiple_whitespaces', (True,)),\n",
       "             ('roman_numerals', (True,))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE⁄DT⁄The PICTURE⁄NN⁄Picture OF⁄IN⁄Of DORIAN⁄JJ⁄Dorian GRAY⁄NNP⁄Gray BY⁄IN⁄By OSCAR⁄NNP⁄Oscar WILDE⁄NNP⁄Wilde\n",
      "The⁄DT⁄The artist⁄NN⁄artist is⁄VBZ⁄be the⁄DT⁄the creator⁄NN⁄creator of⁄IN⁄of beautiful⁄JJ⁄beautiful things⁄NNS⁄thing\n",
      "PREFACE⁄NN⁄Preface\n"
     ]
    }
   ],
   "source": [
    "# класс Text может принять в качестве ввода непосредственно текст (нужно указать это в параметре input='text', \n",
    "# по дефолту input=\"filename\")\n",
    "intake='''THE PICTURE OF DORIAN GRAY\n",
    "\n",
    "BY\n",
    "\n",
    "OSCAR WILDE. The artist is the creator of beautiful things. PREFACE'''\n",
    "text1 = Text(intake, prep, clean, filters, input='text', inplace=True)\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5, 'THE PICTURE OF DORIAN GRAY BY OSCAR WILDE'),\n",
       " (0.5, 'The artist is the creator of beautiful things')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.summarize(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedSentence(\n",
       " \t'THE⁄DT⁄The PICTURE⁄NN⁄Picture OF⁄IN⁄Of DORIAN⁄JJ⁄Dorian GRAY⁄NNP⁄Gray BY⁄IN⁄By OSCAR⁄NNP⁄Oscar WILDE⁄NNP⁄Wilde',\n",
       " \t n=0\n",
       " ), TaggedSentence(\n",
       " \t'The⁄DT⁄The artist⁄NN⁄artist is⁄VBZ⁄be the⁄DT⁄the creator⁄NN⁄creator of⁄IN⁄of beautiful⁄JJ⁄beautiful things⁄NNS⁄thing',\n",
       " \t n=1\n",
       " ), TaggedSentence(\n",
       " \t'PREFACE⁄NN⁄Preface',\n",
       " \t n=2\n",
       " )]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedSentence(\n",
       " \t'THE⁄DT⁄The PICTURE⁄NN⁄Picture OF⁄IN⁄Of DORIAN⁄JJ⁄Dorian GRAY⁄NNP⁄Gray BY⁄IN⁄By OSCAR⁄NNP⁄Oscar WILDE⁄NNP⁄Wilde',\n",
       " \t n=0\n",
       " ), TaggedSentence(\n",
       " \t'The⁄DT⁄The artist⁄NN⁄artist is⁄VBZ⁄be the⁄DT⁄the creator⁄NN⁄creator of⁄IN⁄of beautiful⁄JJ⁄beautiful things⁄NNS⁄thing',\n",
       " \t n=1\n",
       " ), TaggedSentence(\n",
       " \t'PREFACE⁄NN⁄Preface',\n",
       " \t n=2\n",
       " )]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "d = pickle.dumps(text1.sents())\n",
    "s = pickle.loads(d)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Token(word='The', idx=0, pos='DT', lemma='The', nsent=1),\n",
       " Token(word='artist', idx=1, pos='NN', lemma='artist', nsent=1),\n",
       " Token(word='is', idx=2, pos='VBZ', lemma='be', nsent=1),\n",
       " Token(word='the', idx=3, pos='DT', lemma='the', nsent=1),\n",
       " Token(word='creator', idx=4, pos='NN', lemma='creator', nsent=1),\n",
       " Token(word='of', idx=5, pos='IN', lemma='of', nsent=1),\n",
       " Token(word='beautiful', idx=6, pos='JJ', lemma='beautiful', nsent=1),\n",
       " Token(word='things', idx=7, pos='NNS', lemma='thing', nsent=1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.sents(1).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the', 'artist', 'is', 'the', 'creator', 'of', 'beautiful', 'things')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.sents(1).words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('creator', 'things', 'beautiful', 'the', 'artist', 'is', 'of')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.sents(1).words(uniq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The⁄DT⁄The artist⁄NN⁄artist is⁄VBZ⁄be the⁄DT⁄the creator⁄NN⁄creator of⁄IN⁄of beautiful⁄JJ⁄beautiful things⁄NNS⁄thing'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.sents(1).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The artist is the creator of beautiful things'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.sents(1).raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THE',\n",
       " 'PICTURE',\n",
       " 'OF',\n",
       " 'DORIAN',\n",
       " 'GRAY',\n",
       " 'BY',\n",
       " 'OSCAR',\n",
       " 'WILDE',\n",
       " 'The',\n",
       " 'artist',\n",
       " 'is',\n",
       " 'the',\n",
       " 'creator',\n",
       " 'of',\n",
       " 'beautiful',\n",
       " 'things',\n",
       " 'PREFACE']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.words(lower=False, filtrate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'picture',\n",
       " 'of',\n",
       " 'dorian',\n",
       " 'gray',\n",
       " 'by',\n",
       " 'oscar',\n",
       " 'wilde',\n",
       " 'the',\n",
       " 'artist',\n",
       " 'is',\n",
       " 'the',\n",
       " 'creator',\n",
       " 'of',\n",
       " 'beautiful',\n",
       " 'things',\n",
       " 'preface']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.words(lower=True, filtrate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['picture',\n",
       " 'wilde',\n",
       " 'things',\n",
       " 'of',\n",
       " 'is',\n",
       " 'by',\n",
       " 'creator',\n",
       " 'the',\n",
       " 'artist',\n",
       " 'preface',\n",
       " 'dorian',\n",
       " 'beautiful',\n",
       " 'gray',\n",
       " 'oscar']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.words(lower=True, filtrate=False, uniq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('THE', 'DT', 'The'),\n",
       " ('PICTURE', 'NN', 'Picture'),\n",
       " ('OF', 'IN', 'Of'),\n",
       " ('DORIAN', 'JJ', 'Dorian'),\n",
       " ('GRAY', 'NNP', 'Gray'),\n",
       " ('BY', 'IN', 'By'),\n",
       " ('OSCAR', 'NNP', 'Oscar'),\n",
       " ('WILDE', 'NNP', 'Wilde')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.sents(0).untagging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count(words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count(words=True,token='the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count(words=False, uniq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['of',\n",
       " 'oscar',\n",
       " 'beautiful',\n",
       " 'by',\n",
       " 'be',\n",
       " 'wilde',\n",
       " 'the',\n",
       " 'preface',\n",
       " 'gray',\n",
       " 'artist',\n",
       " 'picture',\n",
       " 'dorian',\n",
       " 'thing',\n",
       " 'creator']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.lemmas(uniq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Picture',\n",
       " 'Of',\n",
       " 'Dorian',\n",
       " 'Gray',\n",
       " 'By',\n",
       " 'Oscar',\n",
       " 'Wilde',\n",
       " 'The',\n",
       " 'artist',\n",
       " 'be',\n",
       " 'the',\n",
       " 'creator',\n",
       " 'of',\n",
       " 'beautiful',\n",
       " 'thing',\n",
       " 'Preface']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.lemmas(lower=False, filtrate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count(words=False,uniq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count(words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'dorian': 1, 'beautiful': 1})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.postags(pos='JJ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beautiful things',\n",
       " 'dorian gray',\n",
       " 'oscar wilde',\n",
       " 'creator',\n",
       " 'preface',\n",
       " 'picture',\n",
       " 'artist']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.keywords().topn(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The⁄DT⁄The Picture⁄NN⁄Picture of⁄IN⁄of Dorian⁄JJ⁄Dorian Gray⁄NNP⁄Gray By⁄IN⁄By Oscar⁄NNP⁄Oscar Wilde⁄NNP⁄Wilde\n"
     ]
    }
   ],
   "source": [
    "intake = 'The Picture of Dorian Gray By Oscar Wilde'\n",
    "text2 = Text(intake, prep, clean, filters, input='text', inplace=True)\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT', 'The'),\n",
       " ('Picture', 'NN', 'Picture'),\n",
       " ('of', 'IN', 'of'),\n",
       " ('Dorian', 'JJ', 'Dorian'),\n",
       " ('Gray', 'NNP', 'Gray'),\n",
       " ('By', 'IN', 'By'),\n",
       " ('Oscar', 'NNP', 'Oscar'),\n",
       " ('Wilde', 'NNP', 'Wilde')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2.sents(0).untagging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text(\n",
      "\tname='StringIO',\n",
      "\tencoding='None',\n",
      "\tnsents=1,\n",
      "\tnwords=8,\n",
      "\tnlemmas=8\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(repr(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## А теперь создадим корпус из коллекции документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method tfidf in module nlptk.mining.text:\n",
      "\n",
      "tfidf(n_doc, token=None, texts: List[List[str]] = [], sort=False, top=0) method of nlptk.mining.text.Corpus instance\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# MODULEDIR это путь до директории каталога nlptk относительно которого мы получаем путь к коллекции документов\n",
    "source = os.path.abspath(os.path.join(nlptk.MODULEDIR,r'corpus\\en'))\n",
    "corpus = Corpus(Path(source,\"*.txt\"), prep, clean, filters)\n",
    "#corpus.saveas = (\"txt\",\"pickle\") # по умолчанию сохраняется в обоих форматах\n",
    "# но загружаться будет согласно тому, что указано в loadas\n",
    "corpus.loadas = \"pickle\"\n",
    "corpus.verbose = False  # при True будет выводить небольшую отладочную информацию об этапах обработки каждого документа\n",
    "#corpus.rewrite = True # перетегировать все тексты, даже если они сохранены \n",
    "#corpus.filtrate = True # применить фильтры при формировании общего вокабуляра; по умолчанию False\n",
    "print(help(corpus.tfidf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "\n",
    "for text in corpus:\n",
    "    # можно выводить объекты текстов text и что-то с ними делать;  по умолчанию объекты  Text генераторы предложений,\n",
    "    # но класс Corpus передает им параметр inplace=True, что заставляет  их отработать на месте \n",
    "    texts.append(text) # в списке texts будут уже отработанные экзмепляры, а не генераторы\n",
    "    #for i,sent in enumerate(text):\n",
    "    #    sent # можно выводить предложения при обработке, но это замедлит работу \n",
    "        \n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus(\n",
      "\tnames=['Austin Pride and Prejudice.txt', 'bronte_jane_txt.txt',...],\n",
      "\tndocs=21,\n",
      "\tnwords=1927580,\n",
      "\tnlemmas=44991,\n",
      "\tnhapaxes=18047\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(repr(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Последнее предложение в корпусе, которое осталось в этой переменной после цикла обработки\n",
    "# сами предложения в объекте корпуса никак не сохраняются в целях экономии памяти. \n",
    "# Сохраняются только всевозможные частотные словари\n",
    "#sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(\n",
       "\tname='wilde_picture_of_dorian_gray_txt',\n",
       "\tencoding='unknown',\n",
       "\tnsents=6506,\n",
       "\tnwords=79794,\n",
       "\tnlemmas=5797\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# работаем с последним текстом, который интерпретатор сохранил в этой переменной\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THE⁄DT⁄The PICTURE⁄NN⁄Picture OF⁄IN⁄Of DORIAN⁄JJ⁄Dorian GRAY⁄NNP⁄Gray '\n",
      " 'BY⁄IN⁄By OSCAR⁄NNP⁄Oscar WILDE⁄NNP⁄Wilde THE⁄DT⁄The PREFACE⁄NNP⁄Preface '\n",
      " 'The⁄DT⁄The artist⁄NN⁄artist is⁄VBZ⁄be the⁄DT⁄the creator⁄NN⁄creator of⁄IN⁄of '\n",
      " 'beautiful⁄JJ⁄beautiful things⁄NNS⁄thing',\n",
      " 'To⁄TO⁄To reveal⁄VB⁄reveal art⁄NN⁄art and⁄CC⁄and conceal⁄VB⁄conceal '\n",
      " 'the⁄DT⁄the artist⁄NN⁄artist is⁄VBZ⁄be art⁄JJ⁄art s⁄NN⁄s aim⁄NN⁄aim',\n",
      " 'The⁄DT⁄The critic⁄NN⁄critic is⁄VBZ⁄be he⁄PRP⁄he who⁄WP⁄who can⁄MD⁄can '\n",
      " 'translate⁄VB⁄translate into⁄IN⁄into another⁄DT⁄another manner⁄NN⁄manner '\n",
      " 'or⁄CC⁄or a⁄DT⁄a new⁄JJ⁄new material⁄NN⁄material his⁄PRP$⁄his '\n",
      " 'impression⁄NN⁄impression of⁄IN⁄of beautiful⁄JJ⁄beautiful things⁄NNS⁄thing',\n",
      " 'The⁄DT⁄The highest⁄JJS⁄high as⁄IN⁄a the⁄DT⁄the lowest⁄JJS⁄low form⁄NN⁄form '\n",
      " 'of⁄IN⁄of criticism⁄NN⁄criticism is⁄VBZ⁄be a⁄DT⁄a mode⁄NN⁄mode of⁄IN⁄of '\n",
      " 'autobiography⁄NN⁄autobiography',\n",
      " 'Those⁄DT⁄Those who⁄WP⁄who find⁄VBP⁄find ugly⁄JJ⁄ugly meanings⁄NNS⁄meaning '\n",
      " 'in⁄IN⁄in beautiful⁄JJ⁄beautiful things⁄NNS⁄thing are⁄VBP⁄be '\n",
      " 'corrupt⁄JJ⁄corrupt without⁄IN⁄without being⁄VBG⁄be charming⁄VBG⁄charm',\n",
      " 'This⁄DT⁄This is⁄VBZ⁄be a⁄DT⁄a fault⁄NN⁄fault',\n",
      " 'Those⁄DT⁄Those who⁄WP⁄who find⁄VBP⁄find beautiful⁄JJ⁄beautiful '\n",
      " 'meanings⁄NNS⁄meaning in⁄IN⁄in beautiful⁄JJ⁄beautiful things⁄NNS⁄thing '\n",
      " 'are⁄VBP⁄be the⁄DT⁄the cultivated⁄JJ⁄cultivated',\n",
      " 'For⁄IN⁄For these⁄DT⁄these there⁄EX⁄there is⁄VBZ⁄be hope⁄NN⁄hope',\n",
      " 'They⁄PRP⁄They are⁄VBP⁄be the⁄DT⁄the elect⁄NN⁄elect to⁄TO⁄to whom⁄WP⁄whom '\n",
      " 'beautiful⁄JJ⁄beautiful things⁄NNS⁄thing mean⁄VBP⁄mean only⁄RB⁄only '\n",
      " 'Beauty⁄NNP⁄Beauty',\n",
      " 'There⁄EX⁄There is⁄VBZ⁄be no⁄DT⁄no such⁄JJ⁄such thing⁄NN⁄thing as⁄IN⁄a a⁄DT⁄a '\n",
      " 'moral⁄JJ⁄moral or⁄CC⁄or an⁄DT⁄an immoral⁄JJ⁄immoral book⁄NN⁄book']\n"
     ]
    }
   ],
   "source": [
    "# объект text при печати на консоль отображается как текст аналогичный сохраненному на диске тегированному тексту\n",
    "pprint(str(text).split(\"\\n\")[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34925"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем общее числу слов в тексте, но после фильтрации\n",
    "len(text.words(filtrate=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79794"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text.words(filtrate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79794"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# число слов в тексте без фильтрации\n",
    "text.nwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1927580"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считаем сколько всего слов есть в корпусе по всем документам\n",
    "sum(corpus.ccfs().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ПРОВЕРЯЕМ ЧТО ПОДСЧЕТЫ ВХОЖДЕНИЙ СЛОВ ОДИНАКОВЫ КАК ДЛЯ ОБЪЕКТОВ ТЕКСТОВ, ТАК И НА УРОВНЕ ВОКАБУЛЯРА КОРПУСА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Austin Pride and Prejudice.txt', 122447),\n",
       " ('bronte_jane_txt.txt', 186971),\n",
       " ('bronte_wuthering_txt.txt', 118794),\n",
       " ('doyle_the_adventures.txt', 105136),\n",
       " ('dreiser_sister.txt', 156304),\n",
       " ('Edgar Allan Poe The Cask of Amontillado.txt', 2335),\n",
       " ('Edgar Allan Poe The Masque of the Red Death.txt', 2419),\n",
       " ('Edgar Allan Poe The Tell-Tale Heart.txt', 2126),\n",
       " ('fitzgerald_great_gatsby_txt.txt', 48484),\n",
       " ('Franz Kafka - Metamorphosis.txt', 22335),\n",
       " ('John Steinbeck - Of Mice and Men.txt', 31025),\n",
       " ('kipling_jungle_book_txt.txt', 51737),\n",
       " ('london_white_txt.txt', 72830),\n",
       " ('stevenson_treasure_island_txt.txt', 69728),\n",
       " ('Stivenson_Fall-or-Dodge-in-Hell_RuLit_Me.txt', 316418),\n",
       " ('stoker_dracula_txt.txt', 161394),\n",
       " ('twain_tom_sawyer_txt.txt', 72935),\n",
       " ('walter_scott_ivanhoe_txt.txt', 194098),\n",
       " ('wells_invisible_man_txt.txt', 49693),\n",
       " ('wells_war_of_the_worlds_txt.txt', 60577),\n",
       " ('wilde_picture_of_dorian_gray_txt.txt', 79794)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(txt.filename,txt.nwords) for txt in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Austin Pride and Prejudice.txt', 122447),\n",
       " ('bronte_jane_txt.txt', 186971),\n",
       " ('bronte_wuthering_txt.txt', 118794),\n",
       " ('doyle_the_adventures.txt', 105136),\n",
       " ('dreiser_sister.txt', 156304),\n",
       " ('Edgar Allan Poe The Cask of Amontillado.txt', 2335),\n",
       " ('Edgar Allan Poe The Masque of the Red Death.txt', 2419),\n",
       " ('Edgar Allan Poe The Tell-Tale Heart.txt', 2126),\n",
       " ('fitzgerald_great_gatsby_txt.txt', 48484),\n",
       " ('Franz Kafka - Metamorphosis.txt', 22335),\n",
       " ('John Steinbeck - Of Mice and Men.txt', 31025),\n",
       " ('kipling_jungle_book_txt.txt', 51737),\n",
       " ('london_white_txt.txt', 72830),\n",
       " ('stevenson_treasure_island_txt.txt', 69728),\n",
       " ('Stivenson_Fall-or-Dodge-in-Hell_RuLit_Me.txt', 316418),\n",
       " ('stoker_dracula_txt.txt', 161394),\n",
       " ('twain_tom_sawyer_txt.txt', 72935),\n",
       " ('walter_scott_ivanhoe_txt.txt', 194098),\n",
       " ('wells_invisible_man_txt.txt', 49693),\n",
       " ('wells_war_of_the_worlds_txt.txt', 60577),\n",
       " ('wilde_picture_of_dorian_gray_txt.txt', 79794)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считаем число слов для каждого текст по сумме частот из каждого словаря cfs\n",
    "# это должно совпасть с тем числом, которое каждый Text хранит в свойстве nwords\n",
    "[(name, sum(corpus.cfs(n).values())) for n,name in enumerate(corpus.filenames())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedSentence(\n",
       "\t'THE⁄DT⁄The PICTURE⁄NN⁄Picture OF⁄IN⁄Of DORIAN⁄JJ⁄Dorian GRAY⁄NNP⁄Gray BY⁄IN⁄By OSCAR⁄NNP⁄Oscar WILDE⁄NNP⁄Wilde THE⁄DT⁄The PREFACE⁄NNP⁄Preface The⁄DT⁄The artist⁄NN⁄artist is⁄VBZ⁄be the⁄DT⁄the creator⁄NN⁄creator of⁄IN⁄of beautiful⁄JJ⁄beautiful things⁄NNS⁄thing',\n",
       "\t n=0\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# объект предложения в виде экземпляра класса TaggedSentence; n это порядковый номер предложения\n",
    "text.sents(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n",
      "18\n",
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# легко догадаться, что это число слов в предложении\n",
    "print(text.sents(0).nwords)\n",
    "print(len(text.sents(0).tokens()))\n",
    "print(len(text.sents(0).words()))\n",
    "print(len(text.sents(0).words(uniq=True)))\n",
    "print(len(text.sents(0).lemmas(uniq=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedSentence(\n",
       " \t'Hallward⁄NN⁄Hallward',\n",
       " \t n=177\n",
       " ), TaggedSentence(\n",
       " \t'Gray⁄NN⁄Gray',\n",
       " \t n=212\n",
       " ), TaggedSentence(\n",
       " \t'Harry⁄NNP⁄Harry',\n",
       " \t n=236\n",
       " )]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# а так мы получаем все предложения из текста не длиннее одного слова\n",
    "text.sents(max_words=1)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedSentence(\n",
       " \t'This⁄DT⁄This is⁄VBZ⁄be a⁄DT⁄a fault⁄NN⁄fault',\n",
       " \t n=5\n",
       " ), TaggedSentence(\n",
       " \t'For⁄IN⁄For these⁄DT⁄these there⁄EX⁄there is⁄VBZ⁄be hope⁄NN⁄hope',\n",
       " \t n=7\n",
       " ), TaggedSentence(\n",
       " \t'That⁄DT⁄That is⁄VBZ⁄be all⁄DT⁄all',\n",
       " \t n=11\n",
       " )]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Давайте усложним условия: не менее трех, но не более пяти слов\n",
    "text.sents(min_words=3,max_words=5)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Token(word='the', idx=0, pos='DT', lemma='the', nsent=0),\n",
       " Token(word='picture', idx=1, pos='NN', lemma='picture', nsent=0),\n",
       " Token(word='of', idx=2, pos='IN', lemma='of', nsent=0),\n",
       " Token(word='dorian', idx=3, pos='JJ', lemma='dorian', nsent=0),\n",
       " Token(word='gray', idx=4, pos='NNP', lemma='gray', nsent=0),\n",
       " Token(word='by', idx=5, pos='IN', lemma='by', nsent=0),\n",
       " Token(word='oscar', idx=6, pos='NNP', lemma='oscar', nsent=0),\n",
       " Token(word='wilde', idx=7, pos='NNP', lemma='wilde', nsent=0),\n",
       " Token(word='the', idx=8, pos='DT', lemma='the', nsent=0),\n",
       " Token(word='preface', idx=9, pos='NNP', lemma='preface', nsent=0),\n",
       " Token(word='the', idx=10, pos='DT', lemma='the', nsent=0),\n",
       " Token(word='artist', idx=11, pos='NN', lemma='artist', nsent=0),\n",
       " Token(word='is', idx=12, pos='VBZ', lemma='be', nsent=0),\n",
       " Token(word='the', idx=13, pos='DT', lemma='the', nsent=0),\n",
       " Token(word='creator', idx=14, pos='NN', lemma='creator', nsent=0),\n",
       " Token(word='of', idx=15, pos='IN', lemma='of', nsent=0),\n",
       " Token(word='beautiful', idx=16, pos='JJ', lemma='beautiful', nsent=0),\n",
       " Token(word='things', idx=17, pos='NNS', lemma='thing', nsent=0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# А если мы хотим получить предложение в более информативном виде? Класс Token к вашим услугам.\n",
    "# Метод tokens трансформирует предложение в список экземпляров этого класса.\n",
    "text.sents(0).tokens(lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Token(word='picture', idx=1, pos='NN', lemma='picture', nsent=0),\n",
       " Token(word='dorian', idx=3, pos='JJ', lemma='dorian', nsent=0),\n",
       " Token(word='gray', idx=4, pos='NNP', lemma='gray', nsent=0),\n",
       " Token(word='oscar', idx=6, pos='NNP', lemma='oscar', nsent=0),\n",
       " Token(word='wilde', idx=7, pos='NNP', lemma='wilde', nsent=0),\n",
       " Token(word='preface', idx=9, pos='NNP', lemma='preface', nsent=0),\n",
       " Token(word='artist', idx=11, pos='NN', lemma='artist', nsent=0),\n",
       " Token(word='creator', idx=14, pos='NN', lemma='creator', nsent=0),\n",
       " Token(word='beautiful', idx=16, pos='JJ', lemma='beautiful', nsent=0),\n",
       " Token(word='things', idx=17, pos='NNS', lemma='thing', nsent=0))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Попробуем включить фильтрацию (это те самые rules_filter, которые мы передавали в объект Corpus, \n",
    "# но которые по умолчанию отключены параметром corpus.filtrate=False, \n",
    "# чтобы в объекте корпуса сохранялась статистика по всем словам\n",
    "text.sents(0).tokens(lower=True,filtrate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the',\n",
       " 'picture',\n",
       " 'of',\n",
       " 'dorian',\n",
       " 'gray',\n",
       " 'by',\n",
       " 'oscar',\n",
       " 'wilde',\n",
       " 'the',\n",
       " 'preface',\n",
       " 'the',\n",
       " 'artist',\n",
       " 'is',\n",
       " 'the',\n",
       " 'creator',\n",
       " 'of',\n",
       " 'beautiful',\n",
       " 'things')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# все слова предложения с указанным номером\n",
    "text.sents(0).words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the',\n",
       " 'picture',\n",
       " 'of',\n",
       " 'dorian',\n",
       " 'gray',\n",
       " 'by',\n",
       " 'oscar',\n",
       " 'wilde',\n",
       " 'the',\n",
       " 'preface',\n",
       " 'the',\n",
       " 'artist',\n",
       " 'be',\n",
       " 'the',\n",
       " 'creator',\n",
       " 'of',\n",
       " 'beautiful',\n",
       " 'thing')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# все леммы предложения с указанным номером\n",
    "text.sents(0).lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('THE', 'DT', 'The'),\n",
       " ('PICTURE', 'NN', 'Picture'),\n",
       " ('OF', 'IN', 'Of'),\n",
       " ('DORIAN', 'JJ', 'Dorian'),\n",
       " ('GRAY', 'NNP', 'Gray'),\n",
       " ('BY', 'IN', 'By'),\n",
       " ('OSCAR', 'NNP', 'Oscar'),\n",
       " ('WILDE', 'NNP', 'Wilde'),\n",
       " ('THE', 'DT', 'The'),\n",
       " ('PREFACE', 'NNP', 'Preface'),\n",
       " ('The', 'DT', 'The'),\n",
       " ('artist', 'NN', 'artist'),\n",
       " ('is', 'VBZ', 'be'),\n",
       " ('the', 'DT', 'the'),\n",
       " ('creator', 'NN', 'creator'),\n",
       " ('of', 'IN', 'of'),\n",
       " ('beautiful', 'JJ', 'beautiful'),\n",
       " ('things', 'NNS', 'thing')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# разтегированное представаление предложения\n",
    "text.sents(0).untagging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('picture', 'artist', 'creator', 'things')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# слова предложения отфильтрованные по частям речи - сущ. (в ед. и мн. числе)\n",
    "text.sents(0).words(pos={\"NN\",\"NNS\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('picture', 'artist', 'creator', 'thing')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# леммы предложения отфильтованные по частям речи - сущ. (в ед. и мн. числе)\n",
    "text.sents(0).lemmas(pos={\"NN\",\"NNS\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('picture', 'gray', 'oscar', 'wilde', 'preface', 'artist', 'creator', 'thing')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# все леммы чей postag начинается на N, то есть любые существительные\n",
    "text.sents(0).lemmas(pos=\"N\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dorian', 'beautiful')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.sents(0).lemmas(pos=\"JJ\")\n",
    "# имя dorian неверно определяется как прилагательное, но здесь играет роль неоднозначность слова, так как такое прилагательное \n",
    "# тоже существует в английском"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE PICTURE OF DORIAN GRAY BY OSCAR WILDE THE PREFACE The artist is the creator of beautiful things'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Предложение как есть, но уже без пунктуации, так как она была удалена на этапе очистки текста фильтрами TextCleaner\n",
    "text.sents(0).raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'picture',\n",
       " 'of',\n",
       " 'dorian',\n",
       " 'gray',\n",
       " 'by',\n",
       " 'oscar',\n",
       " 'wilde',\n",
       " 'the',\n",
       " 'preface']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.words(filtrate=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'be': 3543, 'have': 1579, 'say': 388, 'do': 370, 'go': 294, 'know': 260, 'come': 230, 'look': 207, 'make': 205, 'think': 192, ...})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Можно получить частотные словари по любой части речи\n",
    "verbs = text.postags(\"VERB\")\n",
    "verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('be', 3543),\n",
       " ('have', 1579),\n",
       " ('say', 388),\n",
       " ('do', 370),\n",
       " ('go', 294),\n",
       " ('know', 260),\n",
       " ('come', 230),\n",
       " ('look', 207),\n",
       " ('make', 205),\n",
       " ('think', 192)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# отсортировать по убыванию частоты\n",
    "text.postags(\"VERB\", sort=-1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['be', 'have', 'say', 'do', 'go', 'know', 'come', 'look', 'make', 'think']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выбрать top наиболее частотных \n",
    "text.postags(\"VERB\",top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verbs.hapaxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'dorian': 303, 't': 162, 'good': 138, 'own': 130, 'great': 82, 'little': 82, 'young': 78, 'other': 72, 'such': 65, 'more': 65, ...})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjectives = text.postags(\"ADJ\")\n",
    "adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'s': 2})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possessive = text.postags(\"POS\")[:10]\n",
    "possessive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('picture', 'dorian', 'gray')\n",
      "('picture', 'dorian', 'oscar')\n",
      "('picture', 'dorian', 'wilde')\n",
      "('picture', 'gray', 'oscar')\n",
      "('picture', 'gray', 'wilde')\n",
      "('picture', 'oscar', 'wilde')\n",
      "('dorian', 'gray', 'oscar')\n",
      "('dorian', 'gray', 'wilde')\n",
      "('dorian', 'gray', 'preface')\n",
      "('dorian', 'oscar', 'wilde')\n",
      "('dorian', 'oscar', 'preface')\n",
      "('dorian', 'wilde', 'preface')\n"
     ]
    }
   ],
   "source": [
    "# генерация skipgram из текста (имплементация из nltk)\n",
    "for n,s in enumerate(text.skipgrams(3,2, filtrate=True, words=True)):\n",
    "    print(s)\n",
    "    if n > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<s>', '<s>', 'The')\n",
      "('<s>', 'The', 'Picture')\n",
      "('The', 'Picture', 'Of')\n",
      "('Picture', 'Of', 'Dorian')\n",
      "('Of', 'Dorian', 'Gray')\n",
      "('Dorian', 'Gray', 'By')\n",
      "('Gray', 'By', 'Oscar')\n",
      "('By', 'Oscar', 'Wilde')\n",
      "('Oscar', 'Wilde', 'The')\n",
      "('Wilde', 'The', 'Preface')\n",
      "('The', 'Preface', 'The')\n",
      "('Preface', 'The', 'artist')\n"
     ]
    }
   ],
   "source": [
    "# генерация ngram из текста (имплементация из nltk)\n",
    "for n,s in enumerate(text.ngrams(3, lower=False, pad_left=True, left_pad_symbol='<s>', pad_right=True, right_pad_symbol='</s>')):\n",
    "    print(s)\n",
    "    if n > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 401),\n",
       " (1, 583),\n",
       " (2, 375),\n",
       " (3, 486),\n",
       " (4, 1474),\n",
       " (5, 24),\n",
       " (6, 0),\n",
       " (7, 2),\n",
       " (8, 236),\n",
       " (9, 51),\n",
       " (10, 390),\n",
       " (11, 430),\n",
       " (12, 70),\n",
       " (13, 341),\n",
       " (14, 1289),\n",
       " (15, 567),\n",
       " (16, 356),\n",
       " (17, 1451),\n",
       " (18, 531),\n",
       " (19, 166),\n",
       " (20, 262)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[(n,corpus.cfs(n).get('said',0)) for n in range(corpus.ndocs)]\n",
    "[(n,corpus.cfs(n,'said')) for n in range(corpus.ndocs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.00015978223910706062),\n",
       " (1, 0.00015213410481186327),\n",
       " (2, 0.0001540171352386233),\n",
       " (3, 0.0002255366362268298),\n",
       " (4, 0.00046010787942562473),\n",
       " (5, 0.0005014834861097941),\n",
       " (6, 0),\n",
       " (7, 4.589855519231613e-05),\n",
       " (8, 0.00023749028017461358),\n",
       " (9, 0.00011140803101146338),\n",
       " (10, 0.000613317132186253),\n",
       " (11, 0.0004055080617905132),\n",
       " (12, 4.689429482164278e-05),\n",
       " (13, 0.00023860495040408915),\n",
       " (14, 0.00019875772432161856),\n",
       " (15, 0.00017140676285405884),\n",
       " (16, 0.00023814764440005225),\n",
       " (17, 0.0003647360004216731),\n",
       " (18, 0.0005213526487426482),\n",
       " (19, 0.00013370036898700366),\n",
       " (20, 0.00016020030343623828)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(n,corpus.tfidf(n,'said')) for n in range(corpus.ndocs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " [('holmes', 0.013378570292080937),\n",
       "  ('sherlock', 0.002169412950320131),\n",
       "  ('watson', 0.0014991888798649405),\n",
       "  ('lestrade', 0.0011004018854958346),\n",
       "  ('rucastle', 0.0011004018854958346),\n",
       "  ('mccarthy', 0.001071443941140681),\n",
       "  ('simon', 0.0008946032784825284)],\n",
       " 'doyle_the_adventures.txt')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# набор наиболее весомых по метрике TFIDF слов в каждом тексте\n",
    "res = [(n,\n",
    "        corpus.tfidf(n,sort=-1)[0:7],\n",
    "        name\n",
    "       ) \n",
    "     for n,name in enumerate(corpus.filenames())\n",
    "]\n",
    "# берем текст по индексу 3 - Приключения Шерлока Холмса\n",
    "res[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отображение слов из 3-го текста в порядковый номер в словаре tdidf\n",
    "ordered_by_tfidf = {word:n for n,(word,_) in enumerate(corpus.tfidf(3,sort=-1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordered_by_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# как видим, хотя метрика и дает наибольшие веса словам важным для контекста произведения - именам главных персонажей,\n",
    "# но очень быстро скатывается до уровня частоупотребляемых вместе с этими словами сокращений типа mr.\n",
    "# чья документтная частота очень и очень высока \n",
    "# (но их можно удалять фильтрацией, которую мы на уровне корпуса не включали, поэтому все стоп-слова и остались на месте)\n",
    "\n",
    "# документная частота слова\n",
    "corpus.dfs('mr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "ordered_by_tfidf['mr'] # на  8 месте если упоядочить слова по TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_by_tfidf['said']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# число вхождений в текст по индексу 3\n",
    "corpus.cfs(3,'mr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# документная частота слова \"holmes\"\n",
    "corpus.dfs('holmes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462\n",
      "462\n",
      "462\n",
      "462\n"
     ]
    }
   ],
   "source": [
    "# число вхождений в текст по индексу 3\n",
    "print(corpus.cfs(3,'holmes'))   # число вхождений словоформы\n",
    "print(texts[3].vocab['holmes']) # число вхождений лемм\n",
    "print(texts[3].words(filtrate=False).count('holmes'))\n",
    "print(texts[3].lemmas(filtrate=False).count('holmes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "3\n",
      "15\n",
      "12\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(corpus.cfs(3,'investigation'))       # число вхождений словоформы\n",
    "print(corpus.cfs(3,'investigations'))\n",
    "print(texts[3].vocab.get('investigation')) # число вхождений леммы == числу вхождений словоформ, которые образуют данную лемму\n",
    "print(texts[3].words(filtrate=False).count('investigation'))  # число вхождений словоформы\n",
    "print(texts[3].lemmas(filtrate=False).count('investigation')) # число вхождений леммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6627"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# уникальных лемм\n",
    "texts[3].count(words=False,uniq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8121"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# уникальных слов (без учета регистра)\n",
    "texts[3].count(words=True, uniq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8720"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# уникальных слов (c учетом регистра)\n",
    "texts[3].count(words=True, uniq=True, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105136"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# всего слов с повторами вхождений\n",
    "texts[3].count(words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105136"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3].nwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105136"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# число ключей в дереве == числу всех слов с повторами\n",
    "len(texts[3]._trie.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8121"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(texts[3].words(lower=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8720"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(texts[3].words(lower=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00020712636290766274"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.tfidf(6,\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "486"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.cfs(3,'said')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.dfs('said')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00022664684706076194"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.tfidf(3,'said')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prospero', 0.007551523202290425),\n",
       " ('courtiers', 0.0038881773578561016),\n",
       " ('waltzers', 0.0037757616011452125),\n",
       " ('mummer', 0.0037757616011452125),\n",
       " ('prince', 0.0036805490437174567),\n",
       " ('ebony', 0.0029662764061375003),\n",
       " ('musicians', 0.002413282532933419),\n",
       " ('revellers', 0.002413282532933419),\n",
       " ('suite', 0.002071538600240377),\n",
       " ('sable', 0.0020565044356389405)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.tfidf(6,sort=-1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prospero',\n",
       " 'courtiers',\n",
       " 'waltzers',\n",
       " 'mummer',\n",
       " 'prince',\n",
       " 'ebony',\n",
       " 'musicians',\n",
       " 'revellers',\n",
       " 'suite',\n",
       " 'sable']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# тоже самое (только в виде упорядоченного списка) - с использованием параметра top\n",
    "corpus.tfidf(6,top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method tfidf in module nlptk.mining.text:\n",
      "\n",
      "tfidf(n_doc, texts: List[List[str]] = None, token=None, sort=False) method of nlptk.mining.text.Corpus instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(corpus.tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317\n",
      "186971\n",
      "1\n",
      "0.0016954500965390355\n",
      "3.044522437723423\n",
      "0.005161835860953437\n"
     ]
    }
   ],
   "source": [
    "print(corpus.cfs(1,'rochester'))\n",
    "print(sum(corpus.cfs(1).values()))\n",
    "print(corpus.dfs('rochester'))\n",
    "print(corpus.tf(1,'rochester'))\n",
    "print(corpus.idf('rochester'))\n",
    "print(corpus.tfidf(1,token='rochester'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--cfc--\n",
      "[('the', 4320),\n",
      " ('to', 4127),\n",
      " ('of', 3596),\n",
      " ('and', 3529),\n",
      " ('her', 2216),\n",
      " ('i', 2046),\n",
      " ('a', 1945),\n",
      " ('in', 1861),\n",
      " ('was', 1843),\n",
      " ('she', 1703)]\n",
      "--ccfc--\n",
      "[('the', 104005),\n",
      " ('and', 64431),\n",
      " ('of', 53145),\n",
      " ('to', 51249),\n",
      " ('a', 42386),\n",
      " ('i', 34454),\n",
      " ('in', 29525),\n",
      " ('he', 28953),\n",
      " ('was', 26894),\n",
      " ('it', 24706)]\n",
      "--dfc--\n",
      "[('over', 21),\n",
      " ('once', 21),\n",
      " ('moment', 21),\n",
      " ('a', 21),\n",
      " ('minutes', 21),\n",
      " ('by', 21),\n",
      " ('four', 21),\n",
      " ('not', 21),\n",
      " ('from', 21),\n",
      " ('loud', 21)]\n",
      "--tfidf--\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input(\"--cfc--\")\n",
    "pprint(corpus.cfs(0,sort=-1)[:10])\n",
    "input(\"--ccfc--\")\n",
    "pprint(corpus.ccfs(sort=-1)[:10])\n",
    "input(\"--dfc--\")\n",
    "pprint(corpus.dfs(sort=-1)[:10])\n",
    "input(\"--tfidf--\")\n",
    "\n",
    "#for n in range(corpus.ndocs):\n",
    "#    pprint(corpus.tfidf(n,sort=-1)[:10]) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18047"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# общее число слов-одиночек\n",
    "all_hapaxes = corpus.hapaxes()\n",
    "len(all_hapaxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a-bleeding',\n",
       " 'a-blowing',\n",
       " 'a-buttin',\n",
       " 'a-callin',\n",
       " 'a-chaffin',\n",
       " 'a-changing',\n",
       " 'a-crossin',\n",
       " 'a-doin',\n",
       " 'a-doing',\n",
       " 'a-done']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# н-да, вот что значит не включать фильтрацию на корпусе ...\n",
    "sorted(all_hapaxes)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen',\n",
       " 'rightful',\n",
       " 'morris',\n",
       " 'grown-up',\n",
       " 'newcomers',\n",
       " 'over-scrupulous',\n",
       " 'vexing',\n",
       " 'sarcastic',\n",
       " 'develop',\n",
       " 'solace']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем слова-одиночки для каждого текста в корпусе\n",
    "hapaxes = [(path, corpus.hapaxes(n)) for n,path in enumerate(corpus.filenames())]\n",
    "hapaxes[0][1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Austin Pride and Prejudice.txt', 2472),\n",
       " ('bronte_jane_txt.txt', 5873),\n",
       " ('bronte_wuthering_txt.txt', 4254),\n",
       " ('doyle_the_adventures.txt', 3758),\n",
       " ('dreiser_sister.txt', 4547),\n",
       " ('Edgar Allan Poe The Cask of Amontillado.txt', 545),\n",
       " ('Edgar Allan Poe The Masque of the Red Death.txt', 585),\n",
       " ('Edgar Allan Poe The Tell-Tale Heart.txt', 383),\n",
       " ('fitzgerald_great_gatsby_txt.txt', 3222),\n",
       " ('Franz Kafka - Metamorphosis.txt', 1291),\n",
       " ('John Steinbeck - Of Mice and Men.txt', 1371),\n",
       " ('kipling_jungle_book_txt.txt', 2212),\n",
       " ('london_white_txt.txt', 3190),\n",
       " ('stevenson_treasure_island_txt.txt', 2951),\n",
       " ('Stivenson_Fall-or-Dodge-in-Hell_RuLit_Me.txt', 8813),\n",
       " ('stoker_dracula_txt.txt', 4471),\n",
       " ('twain_tom_sawyer_txt.txt', 3691),\n",
       " ('walter_scott_ivanhoe_txt.txt', 5737),\n",
       " ('wells_invisible_man_txt.txt', 2915),\n",
       " ('wells_war_of_the_worlds_txt.txt', 3330),\n",
       " ('wilde_picture_of_dorian_gray_txt.txt', 3542)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сколько у нас гапаксов на каждый текст\n",
    "[(h[0],len(h[1])) for h in hapaxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Austin Pride and Prejudice.txt', 2472),\n",
       " ('bronte_jane_txt.txt', 5873),\n",
       " ('bronte_wuthering_txt.txt', 4254),\n",
       " ('doyle_the_adventures.txt', 3758),\n",
       " ('dreiser_sister.txt', 4547),\n",
       " ('Edgar Allan Poe The Cask of Amontillado.txt', 545),\n",
       " ('Edgar Allan Poe The Masque of the Red Death.txt', 585),\n",
       " ('Edgar Allan Poe The Tell-Tale Heart.txt', 383),\n",
       " ('fitzgerald_great_gatsby_txt.txt', 3222),\n",
       " ('Franz Kafka - Metamorphosis.txt', 1291),\n",
       " ('John Steinbeck - Of Mice and Men.txt', 1371),\n",
       " ('kipling_jungle_book_txt.txt', 2212),\n",
       " ('london_white_txt.txt', 3190),\n",
       " ('stevenson_treasure_island_txt.txt', 2951),\n",
       " ('Stivenson_Fall-or-Dodge-in-Hell_RuLit_Me.txt', 8813),\n",
       " ('stoker_dracula_txt.txt', 4471),\n",
       " ('twain_tom_sawyer_txt.txt', 3691),\n",
       " ('walter_scott_ivanhoe_txt.txt', 5737),\n",
       " ('wells_invisible_man_txt.txt', 2915),\n",
       " ('wells_war_of_the_worlds_txt.txt', 3330),\n",
       " ('wilde_picture_of_dorian_gray_txt.txt', 3542)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# гапаксы с вычислением по всем словоформам, результат должен быть идентичен коду выше \n",
    "[(txt.filename, len(txt.hapaxes(words=True))) for txt in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Austin Pride and Prejudice.txt', 1835),\n",
       " ('bronte_jane_txt.txt', 4646),\n",
       " ('bronte_wuthering_txt.txt', 3157),\n",
       " ('doyle_the_adventures.txt', 2963),\n",
       " ('dreiser_sister.txt', 3620),\n",
       " ('Edgar Allan Poe The Cask of Amontillado.txt', 486),\n",
       " ('Edgar Allan Poe The Masque of the Red Death.txt', 496),\n",
       " ('Edgar Allan Poe The Tell-Tale Heart.txt', 338),\n",
       " ('fitzgerald_great_gatsby_txt.txt', 2594),\n",
       " ('Franz Kafka - Metamorphosis.txt', 996),\n",
       " ('John Steinbeck - Of Mice and Men.txt', 1073),\n",
       " ('kipling_jungle_book_txt.txt', 1698),\n",
       " ('london_white_txt.txt', 2507),\n",
       " ('stevenson_treasure_island_txt.txt', 2245),\n",
       " ('Stivenson_Fall-or-Dodge-in-Hell_RuLit_Me.txt', 7309),\n",
       " ('stoker_dracula_txt.txt', 3527),\n",
       " ('twain_tom_sawyer_txt.txt', 2862),\n",
       " ('walter_scott_ivanhoe_txt.txt', 4445),\n",
       " ('wells_invisible_man_txt.txt', 2316),\n",
       " ('wells_war_of_the_worlds_txt.txt', 2674),\n",
       " ('wilde_picture_of_dorian_gray_txt.txt', 2806)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# а так гапаксы будут считаться по леммам и, поскольку словарь лемм для каждого текста уже имеется в экземпляре каждого текста, \n",
    "# вычисляется гораздо быстрее\n",
    "[(txt.filename, len(txt.hapaxes())) for txt in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105136\n",
      "3758\n",
      "['wedged', 'wedlock', 'wee', 'weedy', 'weekly', 'weigh', 'weighing', 'weird', 'welcome', 'welcomed', 'well-cut', 'well-groomed', 'well-lit', 'well-nigh', 'well-nurtured', 'well-opened', 'well-remembered', 'wellington', 'westbury', 'western', 'westphail', 'westward', 'wheal', 'wheel', 'wheeled', 'wherever', 'whims', 'whine', 'whined', 'whirling', 'whishing', 'whisper', 'whispering', 'white-aproned', 'white-counterpaned', 'whiten', 'whiter', 'whither', 'whittington', 'wholesome', 'whoso', 'wicker-work', 'wicket', 'widow', 'wig', 'wight', 'wigmore', 'wigs', 'wilderness', 'wilful', 'wilhelm', 'will-o', 'willingly', 'willows', 'wilton', 'wimpole', 'win', 'winced', 'wincing', 'wind-swept', 'windfall', 'window-sill', 'windowsill', 'wine', 'wine-cellar', 'wines', 'winking', 'winter', 'wintry', 'wiry', 'wisdom', 'wishing', 'withdrawn', 'witnesses', 'wits', 'wives', 'woke', 'womanhood', 'wondered', 'wooded', 'wooden-leg', 'wooden-legged', 'worker', 'workmen', 'world-wide', 'worlds', 'worm-eaten', 'worms', 'worry', 'worthless', 'wounded', 'wrack', 'wreath', 'wreaths', 'wrenching', 'wretch', 'wriggled', 'writ', 'writers', 'writes', 'writings', 'x', 'ycuea', 'yell', 'yonder', 'zealand', 'zero', 'zero-point', 'zest', 'zigzag']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndoc = 3\n",
    "print(len(texts[ndoc].words(filtrate=False)))\n",
    "\n",
    "hp = texts[ndoc].hapaxes(words=True)\n",
    "print(len(hp))\n",
    "print(sorted(hp)[-110:len(hp)])\n",
    "'ycuea' in hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105136\n",
      "3758\n",
      "['wedged', 'wedlock', 'wee', 'weedy', 'weekly', 'weigh', 'weighing', 'weird', 'welcome', 'welcomed', 'well-cut', 'well-groomed', 'well-lit', 'well-nigh', 'well-nurtured', 'well-opened', 'well-remembered', 'wellington', 'westbury', 'western', 'westphail', 'westward', 'wheal', 'wheel', 'wheeled', 'wherever', 'whims', 'whine', 'whined', 'whirling', 'whishing', 'whisper', 'whispering', 'white-aproned', 'white-counterpaned', 'whiten', 'whiter', 'whither', 'whittington', 'wholesome', 'whoso', 'wicker-work', 'wicket', 'widow', 'wig', 'wight', 'wigmore', 'wigs', 'wilderness', 'wilful', 'wilhelm', 'will-o', 'willingly', 'willows', 'wilton', 'wimpole', 'win', 'winced', 'wincing', 'wind-swept', 'windfall', 'window-sill', 'windowsill', 'wine', 'wine-cellar', 'wines', 'winking', 'winter', 'wintry', 'wiry', 'wisdom', 'wishing', 'withdrawn', 'witnesses', 'wits', 'wives', 'woke', 'womanhood', 'wondered', 'wooded', 'wooden-leg', 'wooden-legged', 'worker', 'workmen', 'world-wide', 'worlds', 'worm-eaten', 'worms', 'worry', 'worthless', 'wounded', 'wrack', 'wreath', 'wreaths', 'wrenching', 'wretch', 'wriggled', 'writ', 'writers', 'writes', 'writings', 'x', 'ycuea', 'yell', 'yonder', 'zealand', 'zero', 'zero-point', 'zest', 'zigzag']\n"
     ]
    }
   ],
   "source": [
    "print(sum(corpus.cfs(ndoc).values()))\n",
    "ln = len(hapaxes[ndoc][1])\n",
    "print(ln)\n",
    "print(sorted(hapaxes[ndoc][1])[-110:ln])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3].vocab['conan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ycuea',\n",
       " 'aiaeeeneii',\n",
       " 'ia',\n",
       " 'eieae',\n",
       " 'aðoaea',\n",
       " 'walsall',\n",
       " 'manifested',\n",
       " 'mauritius',\n",
       " 'solely',\n",
       " 'survived']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapaxes[3][1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.cfs(3,'manifested')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# общекорпусная частота слова\n",
    "corpus.ccfs('manifested')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "842\n",
      "842\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(corpus.cfs(0,'have'))\n",
    "print(texts[0].words(filtrate=False).count('have'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(\n",
       "\tname='Austin Pride and Prejudice',\n",
       "\tencoding='unknown',\n",
       "\tnsents=5950,\n",
       "\tnwords=122447,\n",
       "\tnlemmas=4950\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122447"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(corpus.cfs(0).values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2083"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.ccfs(\"am\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# частота слова для текста корпуса с номером 0\n",
    "corpus.cfs(0,'vicious')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.cfs(9,\"gregor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7905"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.ccfs(\"s\") # остатки притяжательных окончаний, которые токенизатор отделяет от основы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.dfs('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FreqDist({})\n"
     ]
    }
   ],
   "source": [
    "# тегов притяжательных окончаний нет, так как nltk.tag_pos умеет их определять только в виде \"'s\", а всю пунктуацию \n",
    "# в начале и в конце токена стрипает токенайзер (точнее, обертка вокруг него), поэтому в тексте остаются только токены вида \"s\"\n",
    "pos,_ = texts[10].postags(\"POS\")\n",
    "pprint(pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Gregor', 'NNP'), (\"'s\", 'POS')]\n",
      "[('Gregor', 'NNP'), ('s', 'NN')]\n",
      "[(\"Gregor's\", 'NN')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.pos_tag([\"Gregor\", \"'s\"]))\n",
    "#[('Gregor', 'NNP'), (\"'s\", 'POS')]\n",
    "\n",
    "print(nltk.pos_tag([\"Gregor\", \"s\"]))\n",
    "#[('Gregor', 'NNP'), ('s', 'NN')]\n",
    "\n",
    "# токены в которых притяжательное окончание присутствует tag_pos не умеет определять как NNP, то есть имена собственные\n",
    "print(nltk.pos_tag([\"Gregor's\"]))\n",
    "#[(\"Gregor's\", 'NN')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('troubled', 1),\n",
       " ('transformed', 1),\n",
       " ('vermin', 1),\n",
       " ('armour-like', 1),\n",
       " ('domed', 1),\n",
       " ('divided', 1),\n",
       " ('arches', 1),\n",
       " ('sections', 1),\n",
       " ('bedding', 1),\n",
       " ('cover', 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выводим слова с сортировкой по возрастанию частот\n",
    "corpus.cfs(9,sort=1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['something might happen',\n",
       " 'far from it',\n",
       " 'i m busy',\n",
       " 'bring a light',\n",
       " 'it was delightful',\n",
       " 'i just counted',\n",
       " 'night had fallen',\n",
       " 'something was impending',\n",
       " 'don t know',\n",
       " 'white fang paused']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[12].keywords(rating=('rake', dict(max_words=3))).topn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['And now was acknowledged the presence of the Red Death',\n",
       " 'Blood was its Avatar and its seal the redness and the horror of blood',\n",
       " 'It was in this apartment also that there stood against the western wall a gigantic clock of ebony',\n",
       " 'There were much of the beautiful much of the wanton much of the bizarre something of the terrible and not a little of that which might have excited disgust',\n",
       " 'To and fro in the seven chambers there stalked in fact a multitude of dreams',\n",
       " 'The figure was tall and gaunt and shrouded from head to foot in the habiliments of the grave',\n",
       " 'And then for a moment all is still and all is silent save the voice of the clock',\n",
       " 'But in spite of these things it was a gay and magnificent revel',\n",
       " 'It was in the blue room where stood the prince with a group of pale courtiers by his side',\n",
       " 'But these other apartments were densely crowded and in them beat feverishly the heart of life']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# много памяти для текстов имеющих больше 20 тыс. словоупотреблений... такой вот TextRank\n",
    "print(texts[6].nwords) # рассказ Эдгара По 'Маска Красной Смерти'\n",
    "texts[6].summarize(10, scores=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndoc = 7\n",
    "words =  [set(sent.lemmas(uniq=True)) for sent in texts[ndoc].sents()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6506"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def similarity(s1, s2):\n",
    "        '''Мера сходства - коэффициент Сёренсена - \n",
    "        https://ru.wikipedia.org/wiki/Коэффициент_Сёренсена\n",
    "        отношение количества одинаковых слов в \n",
    "        предложениях к суммарной длине предложений.\n",
    "        ''' \n",
    "        if not len(s1) or not len(s2):\n",
    "            return 0.0\n",
    "        \n",
    "        return len(s1.intersection(s2))/(1.0 * (len(s1) + len(s2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsents = texts[ndoc].nsents    \n",
    "pairs = itertools.combinations(range(nsents), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11378564\n",
      "[(0, 1, 0.125), (0, 2, 0.15151515151515152), (0, 3, 0.125), (0, 4, 0.11538461538461539), (0, 5, 0.05555555555555555), (0, 6, 0.16666666666666666), (0, 7, 0.05263157894736842), (0, 8, 0.16), (0, 9, 0.08), (0, 10, 0.05)]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i, j in pairs:\n",
    "    sim = similarity(words[i], words[j])\n",
    "    if sim:\n",
    "        scores.append((i, j, sim)) \n",
    "    \n",
    "\n",
    "print(len(scores))\n",
    "print(scores[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['free',\n",
       " 'free',\n",
       " 'free',\n",
       " 'free',\n",
       " 'free',\n",
       " 'free',\n",
       " 'free',\n",
       " 'freedom',\n",
       " 'freedom',\n",
       " 'freedom',\n",
       " 'freedom',\n",
       " 'freely',\n",
       " 'freely',\n",
       " 'freely',\n",
       " 'freely']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0].startswith('free')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1103, 37),\n",
       " (1537, 4),\n",
       " (1673, 7),\n",
       " (2910, 19),\n",
       " (3764, 26),\n",
       " (4590, 20),\n",
       " (4938, 22)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0].trie('free')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(\n",
       "\tname='doyle_the_adventures',\n",
       "\tencoding='unknown',\n",
       "\tnsents=6810,\n",
       "\tnwords=105136,\n",
       "\tnlemmas=6627\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'miss', 'missed', 'misses', 'missing', 'mission'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(texts[3].startswith('miss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedSentence(\n",
       "\t'Crime⁄NN⁄Crime is⁄VBZ⁄be common⁄JJ⁄common',\n",
       "\t n=6195\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3].sents(6195)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(27, 11),\n",
       " (448, 19),\n",
       " (702, 37),\n",
       " (703, 21),\n",
       " (1055, 2),\n",
       " (1290, 13),\n",
       " (1571, 18),\n",
       " (1630, 5),\n",
       " (1630, 7),\n",
       " (1688, 6),\n",
       " (1837, 21),\n",
       " (2301, 14),\n",
       " (2591, 23),\n",
       " (2948, 12),\n",
       " (2958, 56),\n",
       " (3270, 13),\n",
       " (3271, 1),\n",
       " (3351, 39),\n",
       " (3353, 1),\n",
       " (3357, 26),\n",
       " (3454, 19),\n",
       " (3528, 9),\n",
       " (3804, 23),\n",
       " (4325, 14),\n",
       " (4398, 12),\n",
       " (5895, 24),\n",
       " (6195, 0),\n",
       " (6197, 10),\n",
       " (6203, 58),\n",
       " (6420, 24),\n",
       " (6423, 3),\n",
       " (6429, 58)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3].trie('crime')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(27, 11),\n",
       " (448, 19),\n",
       " (702, 37),\n",
       " (703, 21),\n",
       " (1055, 2),\n",
       " (1290, 13),\n",
       " (1571, 18),\n",
       " (1630, 5),\n",
       " (1630, 7),\n",
       " (1688, 6),\n",
       " (1837, 21),\n",
       " (2301, 14),\n",
       " (2591, 23),\n",
       " (2948, 12),\n",
       " (2958, 56),\n",
       " (3270, 13),\n",
       " (3271, 1),\n",
       " (3351, 39),\n",
       " (3353, 1),\n",
       " (3357, 26),\n",
       " (3454, 19),\n",
       " (3528, 9),\n",
       " (3804, 23),\n",
       " (4325, 14),\n",
       " (4398, 12),\n",
       " (5895, 24),\n",
       " (6197, 10),\n",
       " (6203, 58),\n",
       " (6420, 24),\n",
       " (6423, 3),\n",
       " (6429, 58)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occurrences = texts[3].trie('crime')\n",
    "occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(27,\n",
       "  'He was still as ever deeply attracted by the study of crime and occupied his immense faculties and extraordinary powers of observation in following out those clues and clearing up those mysteries which had been abandoned as hopeless by the official police'),\n",
       " (448,\n",
       "  'The stage lost a fine actor even as science lost an acute reasoner when he became a specialist in crime'),\n",
       " (702,\n",
       "  'You have heard me remark that the strangest and most unique things are very often connected not with the larger but with the smaller crimes and occasionally indeed where there is room for doubt whether any positive crime has been committed'),\n",
       " (703,\n",
       "  'As far as I have heard it is impossible for me to say whether the present case is an instance of crime or not but the course of events is certainly among the most singular that I have ever listened to'),\n",
       " (1055, 'A considerable crime is in contemplation'),\n",
       " (1290,\n",
       "  'The larger crimes are apt to be the simpler for the bigger the crime the more obvious as a rule is the motive'),\n",
       " (1571,\n",
       "  'I think of writing another little monograph some of these days on the typewriter and its relation to crime'),\n",
       " (1630,\n",
       "  'That fellow will rise from crime to crime until he does something very bad and ends on a gallows'),\n",
       " (1630,\n",
       "  'That fellow will rise from crime to crime until he does something very bad and ends on a gallows'),\n",
       " (1688,\n",
       "  'The more featureless and commonplace a crime is the more difficult it is to bring it home'),\n",
       " (1837,\n",
       "  'I knew your energetic nature and that you would not be happy until you had been on the scene of the crime'),\n",
       " (2301,\n",
       "  'Sherlock Holmes sat moodily at one side of the fireplace cross-indexing his records of crime while I at the other was deep in one of Clark Russell s fine sea-stories until the howl of the gale from without seemed to blend with the text and the splash of the rain to lengthen out into the long swash of the sea waves'),\n",
       " (2591,\n",
       "  'Botany variable geology profound as regards the mud-stains from any region within fifty miles of town chemistry eccentric anatomy unsystematic sensational literature and crime records unique violin-player boxer swordsman lawyer and self-poisoner by cocaine and tobacco'),\n",
       " (2948,\n",
       "  'The rooms were carefully examined and results all pointed to an abominable crime'),\n",
       " (2958,\n",
       "  'The Lascar was known to be a man of the vilest antecedents but as by Mrs St Clair s story he was known to have been at the foot of the stair within a very few seconds of her husband s appearance at the window he could hardly have been more than an accessory to the crime'),\n",
       " (3270,\n",
       "  'If I am Mr Neville St Clair then it is obvious that no crime has been committed and that therefore I am illegally detained'),\n",
       " (3271, 'No crime but a very great error has been committed said Holmes'),\n",
       " (3351,\n",
       "  'I suppose I remarked that homely as it looks this thing has some deadly story linked on to it that it is the clue which will guide you in the solution of some mystery and the punishment of some crime'),\n",
       " (3353, 'No crime said Sherlock Holmes laughing'),\n",
       " (3357,\n",
       "  'So much so I remarked that of the last six cases which I have added to my notes three have been entirely free of any legal crime'),\n",
       " (3454,\n",
       "  'Well it is very ingenious said I laughing but since as you said just now there has been no crime committed and no harm done save the loss of a goose all this seems to be rather a waste of energy'),\n",
       " (3528, 'Of course it is a nucleus and focus of crime'),\n",
       " (3804,\n",
       "  'It is very well to cringe and crawl now but you thought little enough of this poor Horner in the dock for a crime of which he knew nothing'),\n",
       " (4325,\n",
       "  'it s a wicked world and when a clever man turns his brains to crime it is the worst of all'),\n",
       " (4398, 'We are only just in time to prevent some subtle and horrible crime'),\n",
       " (5895,\n",
       "  'I trust sir that you will succeed in proving what I feel sure is the truth that my cousin Arthur is innocent of this crime'),\n",
       " (6197,\n",
       "  'Therefore it is upon the logic rather than upon the crime that you should dwell'),\n",
       " (6203,\n",
       "  'At the same time he remarked after a pause during which he had sat puffing at his long pipe and gazing down into the fire you can hardly be open to a charge of sensationalism for out of these cases which you have been so kind as to interest yourself in a fair proportion do not treat of crime in its legal sense at all'),\n",
       " (6420,\n",
       "  'I look at them and the only thought which comes to me is a feeling of their isolation and of the impunity with which crime may be committed there'),\n",
       " (6423, 'Who would associate crime with these dear old homesteads'),\n",
       " (6429,\n",
       "  'There is no lane so vile that the scream of a tortured child or the thud of a drunkard s blow does not beget sympathy and indignation among the neighbours and then the whole machinery of justice is ever so close that a word of complaint can set it going and there is but a step between the crime and the dock')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(nsent,texts[3].sents(nsent).raw) for nsent,_ in occurrences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 4),\n",
       " (13, 2),\n",
       " (24, 5),\n",
       " (26, 31),\n",
       " (31, 36),\n",
       " (53, 2),\n",
       " (100, 7),\n",
       " (105, 1),\n",
       " (128, 0),\n",
       " (134, 7)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# узнаем в каких предложениях и на каких позициях употреблялось данное слово\n",
    "texts[3].trie('holmes')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'holmes'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3].sents(24).words(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I had seen little of Holmes lately'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3].sents(24).raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'free'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0].sents(1103).words(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In his library he had been always sure of leisure and tranquillity and though prepared as he told Elizabeth to meet with folly and conceit in every other room of the house he was used to be free from them there his civility therefore was most prompt in inviting Mr Collins to join his daughters in their walk and Mr Collins being in fact much better fitted for a walker than a reader was extremely pleased to close his large book and go'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0].sents(1103).raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'free'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0].sents(4938).words(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On the gentlemen s appearing her colour increased yet she received them with tolerable ease and with a propriety of behaviour equally free from any symptom of resentment or any unnecessary complaisance'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0].sents(4938).raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4057"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts[0].trie('the'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156304"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts[4].words(filtrate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156304"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[4].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156304"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts[4]._trie.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6873"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts[0].words(uniq=True, lower=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6873"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0].count(uniq=True, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6382"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts[0].words(uniq=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6382"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0].count(uniq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0].count(words=False,uniq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts[0].lemmas(uniq=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5950,\n",
       " 9709,\n",
       " 6838,\n",
       " 6810,\n",
       " 12527,\n",
       " 235,\n",
       " 101,\n",
       " 166,\n",
       " 3420,\n",
       " 780,\n",
       " 3409,\n",
       " 3207,\n",
       " 4757,\n",
       " 3731,\n",
       " 18262,\n",
       " 9695,\n",
       " 4898,\n",
       " 7341,\n",
       " 3850,\n",
       " 3287,\n",
       " 6506]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[texts[i].nsents for i in range(corpus.ndocs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'be': 4422, 'have': 2082, 'say': 603, 'do': 537, 'come': 340, 'see': 322, 'know': 267, 'go': 248, 'think': 236, 'take': 214, ...})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs = texts[3].postags(\"VERB\")\n",
    "verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('be', 4422),\n",
       " ('have', 2082),\n",
       " ('say', 603),\n",
       " ('do', 537),\n",
       " ('come', 340),\n",
       " ('see', 322),\n",
       " ('know', 267),\n",
       " ('go', 248),\n",
       " ('think', 236),\n",
       " ('take', 214)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3].postags(\"VERB\", sort=-1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedSentence(\n",
       "\t'A⁄DT⁄A Scandal⁄NNP⁄Scandal in⁄IN⁄in Bohemia⁄NNP⁄Bohemia II⁄NNP⁄Ii',\n",
       "\t n=1\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получить ттегированное по частям речи представление прдложения\n",
    "texts[3].sents(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Token(word='a', idx=0, pos='DT', lemma='a', nsent=1),\n",
       " Token(word='scandal', idx=1, pos='NNP', lemma='scandal', nsent=1),\n",
       " Token(word='in', idx=2, pos='IN', lemma='in', nsent=1),\n",
       " Token(word='bohemia', idx=3, pos='NNP', lemma='bohemia', nsent=1),\n",
       " Token(word='ii', idx=4, pos='NNP', lemma='ii', nsent=1))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3].sents(1).tokens(lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['omne ignotum pro magnifico',\n",
       " 'prima donna imperial opera',\n",
       " 'botany variable geology profound',\n",
       " 'civilisation like untamed beasts',\n",
       " 'british barque sophy anderson',\n",
       " 'light mousseline de soie',\n",
       " 'san francisco cal u.s.a',\n",
       " 'settee said holmes relapsing',\n",
       " 'over-clean black frock-coat unbuttoned',\n",
       " 'forts upon portsdown hill']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3].keywords().topn(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
