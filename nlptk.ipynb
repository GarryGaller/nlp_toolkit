{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLPTK: тулкит для Natural Language Processing\n",
    "\n",
    "## Работа с классом Text: основные методы и свойства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# минимально необходимые внешние модули\n",
    "#!pip install chardet\n",
    "#!pip install dawg\n",
    "#!pip install gensim\n",
    "#!pip install pattern\n",
    "#!pip install razdel\n",
    "#!pip install pymorphy2\n",
    "\n",
    "import sys, os\n",
    "# сменим рабочую директорию на ту, где расположен каталог с библиотекой nlptk\n",
    "os.chdir(r'D:\\INSTALL\\Python3\\PROJECTS\\REPOS\\nlp_toolkit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nlptk.mining.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим этот путь в sys.path, чтобы интерпретатор увидел нашу библиотеку\n",
    "sys.path.append(r'D:\\INSTALL\\Python3\\PROJECTS\\REPOS\\nlp_toolkit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pprint import pprint\n",
    "import nlptk\n",
    "from nlptk.mining.text import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentencizer': <function nlptk.misc.mixins.SentencizerMixin.sentencize_nltk(text, *args, lang='english', **kwargs)>,\n",
       " 'tokenizer': functools.partial(<function TokenizerMixin.toktok_tokenize at 0x0E0989C0>, strip='!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'),\n",
       " 'tagger': <function nlptk.misc.mixins.TaggerMixin.tagger_nltk(tokens, *args, lang='eng', **kwargs)>,\n",
       " 'lemmatizer': functools.partial(<function LemmatizerMixin.lemmatize_nltk at 0x0E098780>, pos=True, normalize_uppercase=<method 'capitalize' of 'str' objects>)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создаем экземпляр класса Prep c настройками по умолчанию\n",
    "prep = Prep()\n",
    "# это то, что будет использоваться при обработке текста\n",
    "prep.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# набор правил для очистки текста; применяются на этапе работы с необработанным текстом;\n",
    "rules_clean = OrderedDict(\n",
    "        roman_numerals=(True,) # здесь еще много всяких правил используемых по умолчанию\n",
    ")\n",
    "# набор правил для фильтра токенов; применяются на этапе запроса слов\\токенов\\лемм из тэгированного текста\n",
    "# могут быть включены на уровне составления вокабуляра класса Corpus \n",
    "# (по умолчанию фильтрация выключена, поэтому вокабуляр максимально полный)\n",
    "rules_filter = OrderedDict(\n",
    "        by_tagpos=(True,{},{\"FW\",\"POS\"}), # фильтр по тегам частей речи - игнорировать иностранные слова и possessive ending parent's\n",
    "        punctuation=True, # по умолчанию\n",
    "        short=(True,3),   # по умолчанию\n",
    "        stopwords=True,   # по умолчанию\n",
    "        ifnotin_lexicon=True\n",
    "        #trailing_chars=True\n",
    ")\n",
    "\n",
    "# классы которым передаются правила, сами же экземпляры классов передаются в конструктор класса Text\n",
    "clean = TextCleaner(rules_clean)\n",
    "filters = TokenFilter(rules_filter)   \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hyphenation', (True,)),\n",
       "             ('accent', (True,)),\n",
       "             ('tags', (True,)),\n",
       "             ('urls', (True,)),\n",
       "             ('numeric', (True,)),\n",
       "             ('nonletter_sequences', (True,)),\n",
       "             ('quotes', (True,)),\n",
       "             ('multiple_whitespaces', (True,)),\n",
       "             ('roman_numerals', (True,))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE⁄DT⁄The PICTURE⁄NN⁄Picture OF⁄IN⁄Of DORIAN⁄JJ⁄Dorian GRAY⁄NNP⁄Gray BY⁄IN⁄By OSCAR⁄NNP⁄Oscar WILDE⁄NNP⁄Wilde\n",
      "The⁄DT⁄The artist⁄NN⁄artist is⁄VBZ⁄be the⁄DT⁄the creator⁄NN⁄creator of⁄IN⁄of beautiful⁄JJ⁄beautiful things⁄NNS⁄thing\n",
      "PREFACE⁄NN⁄Preface\n"
     ]
    }
   ],
   "source": [
    "# класс Text может принять в качестве ввода непосредственно текст (нужно указать это в параметре input='text', \n",
    "# по дефолту input=\"filename\")\n",
    "intake='''THE PICTURE OF DORIAN GRAY\n",
    "\n",
    "BY\n",
    "\n",
    "OSCAR WILDE. The artist is the creator of beautiful things. PREFACE'''\n",
    "text1 = Text(intake, prep, clean, filters, input='text', inplace=True)\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5, 'THE PICTURE OF DORIAN GRAY BY OSCAR WILDE'),\n",
       " (0.5, 'The artist is the creator of beautiful things')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.summarize(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedSentence(\n",
       " \t'THE⁄DT⁄The PICTURE⁄NN⁄Picture OF⁄IN⁄Of DORIAN⁄JJ⁄Dorian GRAY⁄NNP⁄Gray BY⁄IN⁄By OSCAR⁄NNP⁄Oscar WILDE⁄NNP⁄Wilde',\n",
       " \t n=0\n",
       " ), TaggedSentence(\n",
       " \t'The⁄DT⁄The artist⁄NN⁄artist is⁄VBZ⁄be the⁄DT⁄the creator⁄NN⁄creator of⁄IN⁄of beautiful⁄JJ⁄beautiful things⁄NNS⁄thing',\n",
       " \t n=1\n",
       " ), TaggedSentence(\n",
       " \t'PREFACE⁄NN⁄Preface',\n",
       " \t n=2\n",
       " )]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Token(word='The', idx=0, pos='DT', lemma='The', nsent=1),\n",
       " Token(word='artist', idx=1, pos='NN', lemma='artist', nsent=1),\n",
       " Token(word='is', idx=2, pos='VBZ', lemma='be', nsent=1),\n",
       " Token(word='the', idx=3, pos='DT', lemma='the', nsent=1),\n",
       " Token(word='creator', idx=4, pos='NN', lemma='creator', nsent=1),\n",
       " Token(word='of', idx=5, pos='IN', lemma='of', nsent=1),\n",
       " Token(word='beautiful', idx=6, pos='JJ', lemma='beautiful', nsent=1),\n",
       " Token(word='things', idx=7, pos='NNS', lemma='thing', nsent=1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.sents(1).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the', 'artist', 'is', 'the', 'creator', 'of', 'beautiful', 'things')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.sents(1).words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('creator', 'things', 'beautiful', 'the', 'artist', 'is', 'of')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.sents(1).words(uniq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The⁄DT⁄The artist⁄NN⁄artist is⁄VBZ⁄be the⁄DT⁄the creator⁄NN⁄creator of⁄IN⁄of beautiful⁄JJ⁄beautiful things⁄NNS⁄thing'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.sents(1).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The artist is the creator of beautiful things'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.sents(1).raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THE',\n",
       " 'PICTURE',\n",
       " 'OF',\n",
       " 'DORIAN',\n",
       " 'GRAY',\n",
       " 'BY',\n",
       " 'OSCAR',\n",
       " 'WILDE',\n",
       " 'The',\n",
       " 'artist',\n",
       " 'is',\n",
       " 'the',\n",
       " 'creator',\n",
       " 'of',\n",
       " 'beautiful',\n",
       " 'things',\n",
       " 'PREFACE']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.words(lower=False, filtrate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'picture',\n",
       " 'of',\n",
       " 'dorian',\n",
       " 'gray',\n",
       " 'by',\n",
       " 'oscar',\n",
       " 'wilde',\n",
       " 'the',\n",
       " 'artist',\n",
       " 'is',\n",
       " 'the',\n",
       " 'creator',\n",
       " 'of',\n",
       " 'beautiful',\n",
       " 'things',\n",
       " 'preface']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.words(lower=True, filtrate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['picture',\n",
       " 'wilde',\n",
       " 'things',\n",
       " 'of',\n",
       " 'is',\n",
       " 'by',\n",
       " 'creator',\n",
       " 'the',\n",
       " 'artist',\n",
       " 'preface',\n",
       " 'dorian',\n",
       " 'beautiful',\n",
       " 'gray',\n",
       " 'oscar']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.words(lower=True, filtrate=False, uniq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('THE', 'DT', 'The'),\n",
       " ('PICTURE', 'NN', 'Picture'),\n",
       " ('OF', 'IN', 'Of'),\n",
       " ('DORIAN', 'JJ', 'Dorian'),\n",
       " ('GRAY', 'NNP', 'Gray'),\n",
       " ('BY', 'IN', 'By'),\n",
       " ('OSCAR', 'NNP', 'Oscar'),\n",
       " ('WILDE', 'NNP', 'Wilde')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.sents(0).untagging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count(\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count(\"words\",uniq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count(\"lemmas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count(\"lemmas\",uniq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count(\"lemmas\",uniq=True,pos='JJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'dorian': 1, 'beautiful': 1})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.postags(pos='JJ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oscar wilde',\n",
       " 'dorian gray',\n",
       " 'beautiful things',\n",
       " 'picture',\n",
       " 'preface',\n",
       " 'artist',\n",
       " 'creator']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.keywords().topn(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The⁄DT⁄The Picture⁄NN⁄Picture of⁄IN⁄of Dorian⁄JJ⁄Dorian Gray⁄NNP⁄Gray By⁄IN⁄By Oscar⁄NNP⁄Oscar Wilde⁄NNP⁄Wilde\n"
     ]
    }
   ],
   "source": [
    "intake = 'The Picture of Dorian Gray By Oscar Wilde'\n",
    "text2 = Text(intake, prep, clean, filters, input='text', inplace=True)\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT', 'The'),\n",
       " ('Picture', 'NN', 'Picture'),\n",
       " ('of', 'IN', 'of'),\n",
       " ('Dorian', 'JJ', 'Dorian'),\n",
       " ('Gray', 'NNP', 'Gray'),\n",
       " ('By', 'IN', 'By'),\n",
       " ('Oscar', 'NNP', 'Oscar'),\n",
       " ('Wilde', 'NNP', 'Wilde')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2.sents(0).untagging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text(\n",
      "\tname='StringIO',\n",
      "\tnsents=1,\n",
      "\tnwords=8,\n",
      "\tnlemmas=8\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(repr(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## А теперь создадим корпус из коллекции документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method tfidf in module nlptk.mining.text:\n",
      "\n",
      "tfidf(n_doc, token=None, texts: List[List[str]] = [], sort=False, top=0) method of nlptk.mining.text.Corpus instance\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# MODULEDIR это путь до директории каталога nlptk относительно которого мы получаем путь к коллекции документов\n",
    "source = os.path.abspath(os.path.join(nlptk.MODULEDIR,r'corpus\\en'))\n",
    "corpus = Corpus(Path(source,\"*.txt\"), prep, clean, filters)\n",
    "corpus.verbose = True  # при True будет выводить небольшую отладочную информацию об этапах обработки каждого документа\n",
    "#corpus.rewrite = True # перетегировать все тексты, даже если они сохранены \n",
    "#corpus.filtrate = True # применить фильтры при формировании общего вокабуляра; по умолчанию False\n",
    "print(help(corpus.tfidf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading:   ..\\mining\\data\\Austin Pride and Prejudice.txt\n",
      "elapsed:   3.1801819801330566\n",
      "vocab: ['pride', 'and', 'prejudice', 'jane', 'austen', 'chapter', 'it', 'is', 'a',...]\n",
      "add vocab: 4.085233688354492\n",
      "reading:   ..\\mining\\data\\bronte_jane_txt.txt\n",
      "elapsed:   8.901509046554565\n",
      "vocab: ['jane', 'eyre', 'by', 'charlotte', 'bronte', 'preface', 'a', 'preface',...]\n",
      "add vocab: 10.415595769882202\n",
      "reading:   ..\\mining\\data\\bronte_wuthering_txt.txt\n",
      "elapsed:   4.319247007369995\n",
      "vocab: ['wuthering', 'heights', 'emily', 'bronte', 'chapter', 'i', 'i', 'have',...]\n",
      "add vocab: 5.397308588027954\n",
      "reading:   ..\\mining\\data\\doyle_the_adventures.txt\n",
      "elapsed:   3.574204444885254\n",
      "vocab: ['the', 'adventures', 'of', 'sherlock', 'holmes', 'by', 'sir', 'arthur',...]\n",
      "add vocab: 4.5972630977630615\n",
      "reading:   ..\\mining\\data\\dreiser_sister.txt\n",
      "elapsed:   7.708440780639648\n",
      "vocab: ['sister', 'carrie', 'by', 'theodore', 'dreiser', 'chapter', 'i', 'the',...]\n",
      "add vocab: 9.20452618598938\n",
      "reading:   ..\\mining\\data\\Edgar Allan Poe The Cask of Amontillado.txt\n",
      "elapsed:   0.08600497245788574\n",
      "vocab: ['the', 'thousand', 'injuries', 'of', 'fortunato', 'i', 'had', 'borne',...]\n",
      "add vocab: 0.4350249767303467\n",
      "reading:   ..\\mining\\data\\Edgar Allan Poe The Masque of the Red Death.txt\n",
      "elapsed:   0.07200407981872559\n",
      "vocab: ['the', 'red', 'death', 'had', 'long', 'devastated', 'the', 'country', 'no',...]\n",
      "add vocab: 0.41802406311035156\n",
      "reading:   ..\\mining\\data\\Edgar Allan Poe The Tell-Tale Heart.txt\n",
      "elapsed:   0.06400346755981445\n",
      "vocab: ['true', 'nervous', 'very', 'very', 'dreadfully', 'nervous', 'i', 'had',...]\n",
      "add vocab: 0.41002345085144043\n",
      "reading:   ..\\mining\\data\\fitzgerald_great_gatsby_txt.txt\n",
      "elapsed:   1.5770900249481201\n",
      "vocab: ['francis', 'scott', 'fitzgerald', 'the', 'great', 'gatsby', 'annotation',...]\n",
      "add vocab: 2.3481342792510986\n",
      "reading:   ..\\mining\\data\\Franz Kafka - Metamorphosis.txt\n",
      "elapsed:   0.32301855087280273\n",
      "vocab: ['i', 'one', 'morning', 'when', 'gregor', 'samsa', 'woke', 'from',...]\n",
      "add vocab: 0.8830506801605225\n",
      "reading:   ..\\mining\\data\\John Steinbeck - Of Mice and Men.txt\n",
      "elapsed:   0.8500487804412842\n",
      "vocab: ['one', 'a', 'few', 'miles', 'south', 'of', 'soledad', 'the', 'salinas',...]\n",
      "add vocab: 1.5140864849090576\n",
      "reading:   ..\\mining\\data\\kipling_jungle_book_txt.txt\n",
      "elapsed:   1.1620659828186035\n",
      "vocab: ['the', 'jungle', 'book', 'rudyard', 'kipling', 'contents', 'mowgli', 's',...]\n",
      "add vocab: 2.0101146697998047\n",
      "reading:   ..\\mining\\data\\london_white_txt.txt\n",
      "elapsed:   2.162123918533325\n",
      "vocab: ['white', 'fang', 'author', 'jack', 'london', 'white', 'fang', 'part', 'i',...]\n",
      "add vocab: 3.219184160232544\n",
      "reading:   ..\\mining\\data\\stevenson_treasure_island_txt.txt\n",
      "elapsed:   1.8801076412200928\n",
      "vocab: ['treasure', 'island', 'robert', 'louis', 'stevenson', 'to', 'lloyd',...]\n",
      "add vocab: 2.9461686611175537\n",
      "reading:   ..\\mining\\data\\Stivenson_Fall-or-Dodge-in-Hell_RuLit_Me.txt\n",
      "elapsed:   22.480286121368408\n",
      "vocab: ['neal', 'stephenson', 'fall', 'or', 'dodge', 'in', 'hell', 'to', 'o', 'l']\n",
      "add vocab: 25.51345944404602\n",
      "reading:   ..\\mining\\data\\stoker_dracula_txt.txt\n",
      "elapsed:   6.164352655410767\n",
      "vocab: ['dracula', 'by', 'bram', 'stoker', 'edition', 'chapter', 'jonathan',...]\n",
      "add vocab: 8.029459238052368\n",
      "reading:   ..\\mining\\data\\twain_tom_sawyer_txt.txt\n",
      "elapsed:   2.3611350059509277\n",
      "vocab: ['the', 'adventures', 'of', 'tom', 'sawyer', 'by', 'mark', 'twain',...]\n",
      "add vocab: 3.6702098846435547\n",
      "reading:   ..\\mining\\data\\walter_scott_ivanhoe_txt.txt\n",
      "elapsed:   6.471370220184326\n",
      "vocab: ['ivanhoe', 'by', 'walter', 'scott', 'now', 'fitted', 'the', 'halter',...]\n",
      "add vocab: 8.749500513076782\n",
      "reading:   ..\\mining\\data\\wells_invisible_man_txt.txt\n",
      "elapsed:   1.559089183807373\n",
      "vocab: ['the', 'invisible', 'man', 'a', 'grotesque', 'romance', 'by', 'h', 'g',...]\n",
      "add vocab: 2.85416316986084\n",
      "reading:   ..\\mining\\data\\wells_war_of_the_worlds_txt.txt\n",
      "elapsed:   1.5800905227661133\n",
      "vocab: ['the', 'war', 'of', 'the', 'worlds', 'by', 'h', 'g', 'wells', 'but']\n",
      "add vocab: 2.995171308517456\n",
      "reading:   ..\\mining\\data\\wilde_picture_of_dorian_gray_txt.txt\n",
      "elapsed:   2.9291677474975586\n",
      "vocab: ['the', 'picture', 'of', 'dorian', 'gray', 'by', 'oscar', 'wilde', 'the',...]\n",
      "add vocab: 4.522258758544922\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "\n",
    "for text in corpus:\n",
    "    # можно выводить объекты текстов text и что-то с ними делать;  по умолчанию объекты  Text генераторы предложений,\n",
    "    # но класс Corpus передает им параметр inplace=True, что заставляет  их отработать на месте \n",
    "    texts.append(text) # в списке texts будут уже отработанные экзмепляры, а не генераторы\n",
    "    #for i,sent in enumerate(text):\n",
    "    #    sent # можно выводить предложения при обработке, но это замедлит работу \n",
    "        \n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus(\n",
      "\tnames=[],\n",
      "\tndocs=0,\n",
      "\tnwords=0,\n",
      "\tnlemmas=0,\n",
      "\tnhapaxes=0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(repr(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedSentence(\n",
       "\t'THE⁄DT⁄The END⁄NN⁄End',\n",
       "\t n=6503\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Последнее предложение в корпусе, которое осталось в этой переменной после цикла обработки\n",
    "# сами предложения в объекте корпуса никак не сохраняются в целях экономии памяти. \n",
    "# Сохраняются только всевозможные частотные словари\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(\n",
       "\tname='wilde_picture_of_dorian_gray_txt',\n",
       "\tnsents=6506,\n",
       "\tnwords=79794,\n",
       "\tnlemmas=5797\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# работаем с последним текстом, который интерпретатор сохранил в этой переменной\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THE⁄DT⁄The PICTURE⁄NN⁄Picture OF⁄IN⁄Of DORIAN⁄JJ⁄Dorian GRAY⁄NNP⁄Gray '\n",
      " 'BY⁄IN⁄By OSCAR⁄NNP⁄Oscar WILDE⁄NNP⁄Wilde THE⁄DT⁄The PREFACE⁄NNP⁄Preface '\n",
      " 'The⁄DT⁄The artist⁄NN⁄artist is⁄VBZ⁄be the⁄DT⁄the creator⁄NN⁄creator of⁄IN⁄of '\n",
      " 'beautiful⁄JJ⁄beautiful things⁄NNS⁄thing',\n",
      " 'To⁄TO⁄To reveal⁄VB⁄reveal art⁄NN⁄art and⁄CC⁄and conceal⁄VB⁄conceal '\n",
      " 'the⁄DT⁄the artist⁄NN⁄artist is⁄VBZ⁄be art⁄JJ⁄art s⁄NN⁄s aim⁄NN⁄aim',\n",
      " 'The⁄DT⁄The critic⁄NN⁄critic is⁄VBZ⁄be he⁄PRP⁄he who⁄WP⁄who can⁄MD⁄can '\n",
      " 'translate⁄VB⁄translate into⁄IN⁄into another⁄DT⁄another manner⁄NN⁄manner '\n",
      " 'or⁄CC⁄or a⁄DT⁄a new⁄JJ⁄new material⁄NN⁄material his⁄PRP$⁄his '\n",
      " 'impression⁄NN⁄impression of⁄IN⁄of beautiful⁄JJ⁄beautiful things⁄NNS⁄thing',\n",
      " 'The⁄DT⁄The highest⁄JJS⁄high as⁄IN⁄a the⁄DT⁄the lowest⁄JJS⁄low form⁄NN⁄form '\n",
      " 'of⁄IN⁄of criticism⁄NN⁄criticism is⁄VBZ⁄be a⁄DT⁄a mode⁄NN⁄mode of⁄IN⁄of '\n",
      " 'autobiography⁄NN⁄autobiography',\n",
      " 'Those⁄DT⁄Those who⁄WP⁄who find⁄VBP⁄find ugly⁄JJ⁄ugly meanings⁄NNS⁄meaning '\n",
      " 'in⁄IN⁄in beautiful⁄JJ⁄beautiful things⁄NNS⁄thing are⁄VBP⁄be '\n",
      " 'corrupt⁄JJ⁄corrupt without⁄IN⁄without being⁄VBG⁄be charming⁄VBG⁄charm',\n",
      " 'This⁄DT⁄This is⁄VBZ⁄be a⁄DT⁄a fault⁄NN⁄fault',\n",
      " 'Those⁄DT⁄Those who⁄WP⁄who find⁄VBP⁄find beautiful⁄JJ⁄beautiful '\n",
      " 'meanings⁄NNS⁄meaning in⁄IN⁄in beautiful⁄JJ⁄beautiful things⁄NNS⁄thing '\n",
      " 'are⁄VBP⁄be the⁄DT⁄the cultivated⁄JJ⁄cultivated',\n",
      " 'For⁄IN⁄For these⁄DT⁄these there⁄EX⁄there is⁄VBZ⁄be hope⁄NN⁄hope',\n",
      " 'They⁄PRP⁄They are⁄VBP⁄be the⁄DT⁄the elect⁄NN⁄elect to⁄TO⁄to whom⁄WP⁄whom '\n",
      " 'beautiful⁄JJ⁄beautiful things⁄NNS⁄thing mean⁄VBP⁄mean only⁄RB⁄only '\n",
      " 'Beauty⁄NNP⁄Beauty',\n",
      " 'There⁄EX⁄There is⁄VBZ⁄be no⁄DT⁄no such⁄JJ⁄such thing⁄NN⁄thing as⁄IN⁄a a⁄DT⁄a '\n",
      " 'moral⁄JJ⁄moral or⁄CC⁄or an⁄DT⁄an immoral⁄JJ⁄immoral book⁄NN⁄book']\n"
     ]
    }
   ],
   "source": [
    "# объект text при печати на консоль отображается как текст аналогичный сохраненному на диске тегированному тексту\n",
    "pprint(str(text).split(\"\\n\")[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34925"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем общее числу слов в тексте, но после фильтрации\n",
    "len(text.words(filtrate=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79794"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text.words(filtrate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79794"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# число слов в тексте без фильтрации\n",
    "text.nwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1927580"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считаем сколько всего слов есть в корпусе по всем документам\n",
    "sum(corpus.ccfs().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ПРОВЕРЯЕМ ЧТО ПОДСЧЕТЫ ВХОЖДЕНИЙ СЛОВ ОДИНАКОВЫ КАК ДЛЯ ОБЪЕКТОВ ТЕКСТОВ, ТАК И НА УРОВНЕ ВОКАБУЛЯРА КОРПУСА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Austin Pride and Prejudice.txt', 122447),\n",
       " ('bronte_jane_txt.txt', 186971),\n",
       " ('bronte_wuthering_txt.txt', 118794),\n",
       " ('doyle_the_adventures.txt', 105136),\n",
       " ('dreiser_sister.txt', 156304),\n",
       " ('Edgar Allan Poe The Cask of Amontillado.txt', 2335),\n",
       " ('Edgar Allan Poe The Masque of the Red Death.txt', 2419),\n",
       " ('Edgar Allan Poe The Tell-Tale Heart.txt', 2126),\n",
       " ('fitzgerald_great_gatsby_txt.txt', 48484),\n",
       " ('Franz Kafka - Metamorphosis.txt', 22335),\n",
       " ('John Steinbeck - Of Mice and Men.txt', 31025),\n",
       " ('kipling_jungle_book_txt.txt', 51737),\n",
       " ('london_white_txt.txt', 72830),\n",
       " ('stevenson_treasure_island_txt.txt', 69728),\n",
       " ('Stivenson_Fall-or-Dodge-in-Hell_RuLit_Me.txt', 316418),\n",
       " ('stoker_dracula_txt.txt', 161394),\n",
       " ('twain_tom_sawyer_txt.txt', 72935),\n",
       " ('walter_scott_ivanhoe_txt.txt', 194098),\n",
       " ('wells_invisible_man_txt.txt', 49693),\n",
       " ('wells_war_of_the_worlds_txt.txt', 60577),\n",
       " ('wilde_picture_of_dorian_gray_txt.txt', 79794)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(txt.filename,txt.nwords) for txt in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Austin Pride and Prejudice.txt', 122447),\n",
       " ('bronte_jane_txt.txt', 186971),\n",
       " ('bronte_wuthering_txt.txt', 118794),\n",
       " ('doyle_the_adventures.txt', 105136),\n",
       " ('dreiser_sister.txt', 156304),\n",
       " ('Edgar Allan Poe The Cask of Amontillado.txt', 2335),\n",
       " ('Edgar Allan Poe The Masque of the Red Death.txt', 2419),\n",
       " ('Edgar Allan Poe The Tell-Tale Heart.txt', 2126),\n",
       " ('fitzgerald_great_gatsby_txt.txt', 48484),\n",
       " ('Franz Kafka - Metamorphosis.txt', 22335),\n",
       " ('John Steinbeck - Of Mice and Men.txt', 31025),\n",
       " ('kipling_jungle_book_txt.txt', 51737),\n",
       " ('london_white_txt.txt', 72830),\n",
       " ('stevenson_treasure_island_txt.txt', 69728),\n",
       " ('Stivenson_Fall-or-Dodge-in-Hell_RuLit_Me.txt', 316418),\n",
       " ('stoker_dracula_txt.txt', 161394),\n",
       " ('twain_tom_sawyer_txt.txt', 72935),\n",
       " ('walter_scott_ivanhoe_txt.txt', 194098),\n",
       " ('wells_invisible_man_txt.txt', 49693),\n",
       " ('wells_war_of_the_worlds_txt.txt', 60577),\n",
       " ('wilde_picture_of_dorian_gray_txt.txt', 79794)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считаем число слов для каждого текст по сумме частот из каждого словаря cfs\n",
    "# это должно совпасть с тем числом, которое каждый Text хранит в свойстве nwords\n",
    "[(name, sum(corpus.cfs(n).values())) for n,name in enumerate(corpus.filenames())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedSentence(\n",
       "\t'THE⁄DT⁄The PICTURE⁄NN⁄Picture OF⁄IN⁄Of DORIAN⁄JJ⁄Dorian GRAY⁄NNP⁄Gray BY⁄IN⁄By OSCAR⁄NNP⁄Oscar WILDE⁄NNP⁄Wilde THE⁄DT⁄The PREFACE⁄NNP⁄Preface The⁄DT⁄The artist⁄NN⁄artist is⁄VBZ⁄be the⁄DT⁄the creator⁄NN⁄creator of⁄IN⁄of beautiful⁄JJ⁄beautiful things⁄NNS⁄thing',\n",
       "\t n=0\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# объект предложения в виде экземпляра класса TaggedSentence; n это порядковый номер предложения\n",
    "text.sents(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n",
      "18\n",
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# легко догадаться, что это число слов в предложении\n",
    "print(text.sents(0).nwords)\n",
    "print(len(text.sents(0).tokens()))\n",
    "print(len(text.sents(0).words()))\n",
    "print(len(text.sents(0).words(uniq=True)))\n",
    "print(len(text.sents(0).lemmas(uniq=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedSentence(\n",
       " \t'Hallward⁄NN⁄Hallward',\n",
       " \t n=177\n",
       " ), TaggedSentence(\n",
       " \t'Gray⁄NN⁄Gray',\n",
       " \t n=212\n",
       " ), TaggedSentence(\n",
       " \t'Harry⁄NNP⁄Harry',\n",
       " \t n=236\n",
       " )]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# а так мы получаем все предложения из текста не длиннее одного слова\n",
    "text.sents(max_words=1)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedSentence(\n",
       " \t'This⁄DT⁄This is⁄VBZ⁄be a⁄DT⁄a fault⁄NN⁄fault',\n",
       " \t n=5\n",
       " ), TaggedSentence(\n",
       " \t'For⁄IN⁄For these⁄DT⁄these there⁄EX⁄there is⁄VBZ⁄be hope⁄NN⁄hope',\n",
       " \t n=7\n",
       " ), TaggedSentence(\n",
       " \t'That⁄DT⁄That is⁄VBZ⁄be all⁄DT⁄all',\n",
       " \t n=11\n",
       " )]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Давайте усложним условия: не менее трех, но не более пяти слов\n",
    "text.sents(min_words=3,max_words=5)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Token(token='the', idx=0, pos='DT', lemma='the', nsent=0),\n",
       " Token(token='picture', idx=1, pos='NN', lemma='picture', nsent=0),\n",
       " Token(token='of', idx=2, pos='IN', lemma='of', nsent=0),\n",
       " Token(token='dorian', idx=3, pos='JJ', lemma='dorian', nsent=0),\n",
       " Token(token='gray', idx=4, pos='NNP', lemma='gray', nsent=0),\n",
       " Token(token='by', idx=5, pos='IN', lemma='by', nsent=0),\n",
       " Token(token='oscar', idx=6, pos='NNP', lemma='oscar', nsent=0),\n",
       " Token(token='wilde', idx=7, pos='NNP', lemma='wilde', nsent=0),\n",
       " Token(token='the', idx=8, pos='DT', lemma='the', nsent=0),\n",
       " Token(token='preface', idx=9, pos='NNP', lemma='preface', nsent=0),\n",
       " Token(token='the', idx=10, pos='DT', lemma='the', nsent=0),\n",
       " Token(token='artist', idx=11, pos='NN', lemma='artist', nsent=0),\n",
       " Token(token='is', idx=12, pos='VBZ', lemma='be', nsent=0),\n",
       " Token(token='the', idx=13, pos='DT', lemma='the', nsent=0),\n",
       " Token(token='creator', idx=14, pos='NN', lemma='creator', nsent=0),\n",
       " Token(token='of', idx=15, pos='IN', lemma='of', nsent=0),\n",
       " Token(token='beautiful', idx=16, pos='JJ', lemma='beautiful', nsent=0),\n",
       " Token(token='things', idx=17, pos='NNS', lemma='thing', nsent=0))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# А если мы хотим получить предложение в более информативном виде? Класс Token к вашим услугам.\n",
    "# Метод tokens трансформирует предложение в список экземпляров этого класса.\n",
    "text.sents(0).tokens(lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Token(token='picture', idx=1, pos='NN', lemma='picture', nsent=0),\n",
       " Token(token='dorian', idx=3, pos='JJ', lemma='dorian', nsent=0),\n",
       " Token(token='gray', idx=4, pos='NNP', lemma='gray', nsent=0),\n",
       " Token(token='oscar', idx=6, pos='NNP', lemma='oscar', nsent=0),\n",
       " Token(token='wilde', idx=7, pos='NNP', lemma='wilde', nsent=0),\n",
       " Token(token='preface', idx=9, pos='NNP', lemma='preface', nsent=0),\n",
       " Token(token='artist', idx=11, pos='NN', lemma='artist', nsent=0),\n",
       " Token(token='creator', idx=14, pos='NN', lemma='creator', nsent=0),\n",
       " Token(token='beautiful', idx=16, pos='JJ', lemma='beautiful', nsent=0),\n",
       " Token(token='things', idx=17, pos='NNS', lemma='thing', nsent=0))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Попробуем включить фильтрацию (это те самые rules_filter, которые мы передавали в объект Corpus, \n",
    "# но которые по умолчанию отключены параметром corpus.filtrate=False, \n",
    "# чтобы в объекте корпуса сохранялась статистика по всем словам\n",
    "text.sents(0).tokens(lower=True,filtrate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the',\n",
       " 'picture',\n",
       " 'of',\n",
       " 'dorian',\n",
       " 'gray',\n",
       " 'by',\n",
       " 'oscar',\n",
       " 'wilde',\n",
       " 'the',\n",
       " 'preface',\n",
       " 'the',\n",
       " 'artist',\n",
       " 'is',\n",
       " 'the',\n",
       " 'creator',\n",
       " 'of',\n",
       " 'beautiful',\n",
       " 'things')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# все слова предложения с указанным номером\n",
    "text.sents(0).words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the',\n",
       " 'picture',\n",
       " 'of',\n",
       " 'dorian',\n",
       " 'gray',\n",
       " 'by',\n",
       " 'oscar',\n",
       " 'wilde',\n",
       " 'the',\n",
       " 'preface',\n",
       " 'the',\n",
       " 'artist',\n",
       " 'be',\n",
       " 'the',\n",
       " 'creator',\n",
       " 'of',\n",
       " 'beautiful',\n",
       " 'thing')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# все леммы предложения с указанным номером\n",
    "text.sents(0).lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('THE', 'DT', 'The'),\n",
       " ('PICTURE', 'NN', 'Picture'),\n",
       " ('OF', 'IN', 'Of'),\n",
       " ('DORIAN', 'JJ', 'Dorian'),\n",
       " ('GRAY', 'NNP', 'Gray'),\n",
       " ('BY', 'IN', 'By'),\n",
       " ('OSCAR', 'NNP', 'Oscar'),\n",
       " ('WILDE', 'NNP', 'Wilde'),\n",
       " ('THE', 'DT', 'The'),\n",
       " ('PREFACE', 'NNP', 'Preface'),\n",
       " ('The', 'DT', 'The'),\n",
       " ('artist', 'NN', 'artist'),\n",
       " ('is', 'VBZ', 'be'),\n",
       " ('the', 'DT', 'the'),\n",
       " ('creator', 'NN', 'creator'),\n",
       " ('of', 'IN', 'of'),\n",
       " ('beautiful', 'JJ', 'beautiful'),\n",
       " ('things', 'NNS', 'thing')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# разтегированное представаление предложения\n",
    "text.sents(0).untagging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('picture', 'artist', 'creator', 'things')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# слова предложения отфильтрованные по частям речи - сущ. (в ед. и мн. числе\n",
    "text.sents(0).words(pos={\"NN\",\"NNS\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('picture', 'artist', 'creator', 'thing')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# леммы предложения отфильтованные по частям речи - сущ. (в ед. и мн. числе)\n",
    "text.sents(0).lemmas(pos={\"NN\",\"NNS\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('picture', 'gray', 'oscar', 'wilde', 'preface', 'artist', 'creator', 'thing')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# все леммы чей postag начинается на N, то есть любые существительные\n",
    "text.sents(0).lemmas(pos=\"N\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dorian', 'beautiful')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.sents(0).lemmas(pos=\"JJ\")\n",
    "# имя dorian неверно определяется как прилагательное, но здесь играет роль неоднозначность слова, так как такое прилагательное \n",
    "# тоже существует в английском"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE PICTURE OF DORIAN GRAY BY OSCAR WILDE THE PREFACE The artist is the creator of beautiful things'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Предложение как есть, но уже без пунктуации, так как она была удалена на этапе очистки текста фильтрами TextCleaner\n",
    "text.sents(0).raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'picture',\n",
       " 'of',\n",
       " 'dorian',\n",
       " 'gray',\n",
       " 'by',\n",
       " 'oscar',\n",
       " 'wilde',\n",
       " 'the',\n",
       " 'preface']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.words(filtrate=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'be': 3543, 'have': 1579, 'say': 388, 'do': 370, 'go': 294, 'know': 260, 'come': 230, 'look': 207, 'make': 205, 'think': 192, ...})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Можно получить частотные словари по любой части речи\n",
    "verbs = text.postags(\"VERB\")[:10]\n",
    "verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verbs.hapaxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'dorian': 303, 't': 162, 'good': 138, 'own': 130, 'great': 82, 'little': 82, 'young': 78, 'other': 72, 'more': 65, 'such': 65, ...})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjectives = text.postags(\"ADJ\")[:10]\n",
    "adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'s': 2})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possessive = text.postags(\"POS\")[:10]\n",
    "possessive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('picture', 'dorian', 'gray')\n",
      "('picture', 'dorian', 'oscar')\n",
      "('picture', 'dorian', 'wilde')\n",
      "('picture', 'gray', 'oscar')\n",
      "('picture', 'gray', 'wilde')\n",
      "('picture', 'oscar', 'wilde')\n",
      "('dorian', 'gray', 'oscar')\n",
      "('dorian', 'gray', 'wilde')\n",
      "('dorian', 'gray', 'preface')\n",
      "('dorian', 'oscar', 'wilde')\n",
      "('dorian', 'oscar', 'preface')\n",
      "('dorian', 'wilde', 'preface')\n"
     ]
    }
   ],
   "source": [
    "# генерация skipgram из текста (имплементация из nltk)\n",
    "for n,s in enumerate(text.skipgrams(3,2)):\n",
    "    print(s)\n",
    "    if n > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('picture', 'dorian', 'gray')\n",
      "('dorian', 'gray', 'oscar')\n",
      "('gray', 'oscar', 'wilde')\n",
      "('oscar', 'wilde', 'preface')\n",
      "('wilde', 'preface', 'artist')\n",
      "('preface', 'artist', 'creator')\n",
      "('artist', 'creator', 'beautiful')\n",
      "('creator', 'beautiful', 'thing')\n",
      "('beautiful', 'thing', 'reveal')\n",
      "('thing', 'reveal', 'art')\n",
      "('reveal', 'art', 'conceal')\n",
      "('art', 'conceal', 'artist')\n"
     ]
    }
   ],
   "source": [
    "# генерация ngram из текста (имплементация из nltk)\n",
    "for n,s in enumerate(text.ngrams(3)):\n",
    "    print(s)\n",
    "    if n > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 401),\n",
       " (1, 583),\n",
       " (2, 375),\n",
       " (3, 486),\n",
       " (4, 1474),\n",
       " (5, 24),\n",
       " (6, 0),\n",
       " (7, 2),\n",
       " (8, 236),\n",
       " (9, 51),\n",
       " (10, 390),\n",
       " (11, 430),\n",
       " (12, 70),\n",
       " (13, 341),\n",
       " (14, 1289),\n",
       " (15, 567),\n",
       " (16, 356),\n",
       " (17, 1451),\n",
       " (18, 531),\n",
       " (19, 166),\n",
       " (20, 262)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[(n,corpus.cfs(n).get('said',0)) for n in range(corpus.ndocs)]\n",
    "[(n,corpus.cfs(n,'said')) for n in range(corpus.ndocs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.00015978223910706062),\n",
       " (1, 0.00015213410481186327),\n",
       " (2, 0.0001540171352386233),\n",
       " (3, 0.0002255366362268298),\n",
       " (4, 0.00046010787942562473),\n",
       " (5, 0.0005014834861097941),\n",
       " (6, 0),\n",
       " (7, 4.589855519231613e-05),\n",
       " (8, 0.00023749028017461358),\n",
       " (9, 0.00011140803101146338),\n",
       " (10, 0.000613317132186253),\n",
       " (11, 0.0004055080617905132),\n",
       " (12, 4.689429482164278e-05),\n",
       " (13, 0.00023860495040408915),\n",
       " (14, 0.00019875772432161856),\n",
       " (15, 0.00017140676285405884),\n",
       " (16, 0.00023814764440005225),\n",
       " (17, 0.0003647360004216731),\n",
       " (18, 0.0005213526487426482),\n",
       " (19, 0.00013370036898700366),\n",
       " (20, 0.00016020030343623828)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(n,corpus.tfidf(n,'said')) for n in range(corpus.ndocs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " [('holmes', 0.013378570292080937),\n",
       "  ('sherlock', 0.002169412950320131),\n",
       "  ('watson', 0.0014991888798649405),\n",
       "  ('lestrade', 0.0011004018854958346),\n",
       "  ('rucastle', 0.0011004018854958346),\n",
       "  ('mccarthy', 0.001071443941140681),\n",
       "  ('simon', 0.0008946032784825284)],\n",
       " 'doyle_the_adventures.txt')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# набор наиболее весомых по метрике TFIDF слов в каждом тексте\n",
    "res = [(n,\n",
    "        corpus.tfidf(n,sort=-1)[0:7],\n",
    "        name\n",
    "       ) \n",
    "     for n,name in enumerate(corpus.filenames())\n",
    "]\n",
    "# берем текст по индексу 3 - Приключения Шерлока Холмса\n",
    "res[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отображение слов из 3-го текста в порядковый номер в словаре tdidf\n",
    "ordered_by_tfidf = {word:n for n,(word,_) in enumerate(corpus.tfidf(3,sort=-1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordered_by_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# как видим, хотя метрика и дает наибольшие веса словам важным для контекста произведения - именам главных персонажей,\n",
    "# но очень быстро скатывается до уровня частоупотребляемых вместе с этими словами сокращений типа mr.\n",
    "# чья документтная частота очень и очень высока \n",
    "# (но их можно удалять фильтрацией, которую мы на уровне корпуса не включали, поэтому все стоп-слова и остались на месте)\n",
    "\n",
    "# документная частота слова\n",
    "corpus.dfs('mr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "ordered_by_tfidf['mr'] # на  8 месте если упоядочить слова по TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_by_tfidf['said']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# число вхождений в текст по индексу 3\n",
    "corpus.cfs(3,'mr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# документная частота слова \"holmes\"\n",
    "corpus.dfs('holmes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462\n",
      "462\n",
      "462\n",
      "462\n"
     ]
    }
   ],
   "source": [
    "# число вхождений в текст по индексу 3\n",
    "print(corpus.cfs(3,'holmes'))   # число вхождений словоформы\n",
    "print(texts[3].vocab['holmes']) # число вхождений лемм\n",
    "print(texts[3].words(filtrate=False).count('holmes'))\n",
    "print(texts[3].lemmas(filtrate=False).count('holmes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "3\n",
      "15\n",
      "12\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(corpus.cfs(3,'investigation'))       # число вхождений словоформы\n",
    "print(corpus.cfs(3,'investigations'))\n",
    "print(texts[3].vocab.get('investigation')) # число вхождений леммы == числу вхождений словоформ, которые образуют данную лемму\n",
    "print(texts[3].words(filtrate=False).count('investigation'))  # число вхождений словоформы\n",
    "print(texts[3].lemmas(filtrate=False).count('investigation')) # число вхождений леммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00020712636290766274"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.tfidf(6,\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "486"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.cfs(3,'said')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.dfs('said')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00022664684706076194"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.tfidf(3,'said')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prospero', 0.007551523202290425),\n",
       " ('courtiers', 0.0038881773578561016),\n",
       " ('waltzers', 0.0037757616011452125),\n",
       " ('mummer', 0.0037757616011452125),\n",
       " ('prince', 0.0036805490437174567),\n",
       " ('ebony', 0.0029662764061375003),\n",
       " ('musicians', 0.002413282532933419),\n",
       " ('revellers', 0.002413282532933419),\n",
       " ('suite', 0.002071538600240377),\n",
       " ('sable', 0.0020565044356389405)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.tfidf(6,sort=-1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prospero',\n",
       " 'courtiers',\n",
       " 'waltzers',\n",
       " 'mummer',\n",
       " 'prince',\n",
       " 'ebony',\n",
       " 'musicians',\n",
       " 'revellers',\n",
       " 'suite',\n",
       " 'sable']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# тоже самое (только в виде упорядоченного списка) - с использованием параметра top\n",
    "corpus.tfidf(6,top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method tfidf in module nlptk.mining.text:\n",
      "\n",
      "tfidf(n_doc, texts: List[List[str]] = None, token=None, sort=False) method of nlptk.mining.text.Corpus instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(corpus.tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312\n",
      "185598\n",
      "1\n",
      "0.0016810525975495426\n",
      "3.044522437723423\n",
      "0.005118002352232825\n"
     ]
    }
   ],
   "source": [
    "print(corpus.cfs(1,'rochester'))\n",
    "print(sum(corpus.cfs(1).values()))\n",
    "print(corpus.dfs('rochester'))\n",
    "print(corpus.tf(1,'rochester'))\n",
    "print(corpus.idf('rochester'))\n",
    "print(corpus.tfidf(1,token='rochester'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--cfc--\n",
      "[('the', 4320),\n",
      " ('to', 4127),\n",
      " ('of', 3596),\n",
      " ('and', 3529),\n",
      " ('her', 2216),\n",
      " ('i', 2046),\n",
      " ('a', 1945),\n",
      " ('in', 1861),\n",
      " ('was', 1843),\n",
      " ('she', 1703)]\n",
      "--ccfc--\n",
      "[('the', 104005),\n",
      " ('and', 64431),\n",
      " ('of', 53145),\n",
      " ('to', 51249),\n",
      " ('a', 42386),\n",
      " ('i', 34454),\n",
      " ('in', 29525),\n",
      " ('he', 28953),\n",
      " ('was', 26894),\n",
      " ('it', 24706)]\n",
      "--dfc--\n",
      "[('over', 21),\n",
      " ('once', 21),\n",
      " ('moment', 21),\n",
      " ('a', 21),\n",
      " ('minutes', 21),\n",
      " ('by', 21),\n",
      " ('four', 21),\n",
      " ('not', 21),\n",
      " ('from', 21),\n",
      " ('loud', 21)]\n",
      "--tfidf--\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input(\"--cfc--\")\n",
    "pprint(corpus.cfs(0,sort=-1)[:10])\n",
    "input(\"--ccfc--\")\n",
    "pprint(corpus.ccfs(sort=-1)[:10])\n",
    "input(\"--dfc--\")\n",
    "pprint(corpus.dfs(sort=-1)[:10])\n",
    "input(\"--tfidf--\")\n",
    "\n",
    "#for n in range(corpus.ndocs):\n",
    "#    pprint(corpus.tfidf(n,sort=-1)[:10]) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18047"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# общее число слов-одиночек\n",
    "all_hapaxes = corpus.hapaxes()\n",
    "len(all_hapaxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a-bleeding',\n",
       " 'a-blowing',\n",
       " 'a-buttin',\n",
       " 'a-callin',\n",
       " 'a-chaffin',\n",
       " 'a-changing',\n",
       " 'a-crossin',\n",
       " 'a-doin',\n",
       " 'a-doing',\n",
       " 'a-done']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# н-да, вот что значит не включать фильтрацию на корпусе ...\n",
    "sorted(all_hapaxes)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen',\n",
       " 'rightful',\n",
       " 'morris',\n",
       " 'grown-up',\n",
       " 'newcomers',\n",
       " 'over-scrupulous',\n",
       " 'vexing',\n",
       " 'sarcastic',\n",
       " 'develop',\n",
       " 'solace']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем слова-одиночки для каждого текста в корпусе\n",
    "hapaxes = [(path, corpus.hapaxes(n)) for n,path in enumerate(corpus.filenames())]\n",
    "hapaxes[0][1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Austin Pride and Prejudice.txt', 2472),\n",
       " ('bronte_jane_txt.txt', 5873),\n",
       " ('bronte_wuthering_txt.txt', 4254),\n",
       " ('doyle_the_adventures.txt', 3758),\n",
       " ('dreiser_sister.txt', 4547),\n",
       " ('Edgar Allan Poe The Cask of Amontillado.txt', 545),\n",
       " ('Edgar Allan Poe The Masque of the Red Death.txt', 585),\n",
       " ('Edgar Allan Poe The Tell-Tale Heart.txt', 383),\n",
       " ('fitzgerald_great_gatsby_txt.txt', 3222),\n",
       " ('Franz Kafka - Metamorphosis.txt', 1291),\n",
       " ('John Steinbeck - Of Mice and Men.txt', 1371),\n",
       " ('kipling_jungle_book_txt.txt', 2212),\n",
       " ('london_white_txt.txt', 3190),\n",
       " ('stevenson_treasure_island_txt.txt', 2951),\n",
       " ('Stivenson_Fall-or-Dodge-in-Hell_RuLit_Me.txt', 8813),\n",
       " ('stoker_dracula_txt.txt', 4471),\n",
       " ('twain_tom_sawyer_txt.txt', 3691),\n",
       " ('walter_scott_ivanhoe_txt.txt', 5737),\n",
       " ('wells_invisible_man_txt.txt', 2915),\n",
       " ('wells_war_of_the_worlds_txt.txt', 3330),\n",
       " ('wilde_picture_of_dorian_gray_txt.txt', 3542)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сколько у нас гапаксов на каждый текст\n",
    "[(h[0],len(h[1])) for h in hapaxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Austin Pride and Prejudice.txt', 2472),\n",
       " ('bronte_jane_txt.txt', 5873),\n",
       " ('bronte_wuthering_txt.txt', 4254),\n",
       " ('doyle_the_adventures.txt', 3758),\n",
       " ('dreiser_sister.txt', 4547),\n",
       " ('Edgar Allan Poe The Cask of Amontillado.txt', 545),\n",
       " ('Edgar Allan Poe The Masque of the Red Death.txt', 585),\n",
       " ('Edgar Allan Poe The Tell-Tale Heart.txt', 383),\n",
       " ('fitzgerald_great_gatsby_txt.txt', 3222),\n",
       " ('Franz Kafka - Metamorphosis.txt', 1291),\n",
       " ('John Steinbeck - Of Mice and Men.txt', 1371),\n",
       " ('kipling_jungle_book_txt.txt', 2212),\n",
       " ('london_white_txt.txt', 3190),\n",
       " ('stevenson_treasure_island_txt.txt', 2951),\n",
       " ('Stivenson_Fall-or-Dodge-in-Hell_RuLit_Me.txt', 8813),\n",
       " ('stoker_dracula_txt.txt', 4471),\n",
       " ('twain_tom_sawyer_txt.txt', 3691),\n",
       " ('walter_scott_ivanhoe_txt.txt', 5737),\n",
       " ('wells_invisible_man_txt.txt', 2915),\n",
       " ('wells_war_of_the_worlds_txt.txt', 3330),\n",
       " ('wilde_picture_of_dorian_gray_txt.txt', 3542)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# гапаксы с вычислением по всем словоформам, результат должен быть идентичен коду выше \n",
    "[(txt.filename, len(txt.hapaxes(words=True))) for txt in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Austin Pride and Prejudice.txt', 1835),\n",
       " ('bronte_jane_txt.txt', 4646),\n",
       " ('bronte_wuthering_txt.txt', 3157),\n",
       " ('doyle_the_adventures.txt', 2963),\n",
       " ('dreiser_sister.txt', 3620),\n",
       " ('Edgar Allan Poe The Cask of Amontillado.txt', 486),\n",
       " ('Edgar Allan Poe The Masque of the Red Death.txt', 496),\n",
       " ('Edgar Allan Poe The Tell-Tale Heart.txt', 338),\n",
       " ('fitzgerald_great_gatsby_txt.txt', 2594),\n",
       " ('Franz Kafka - Metamorphosis.txt', 996),\n",
       " ('John Steinbeck - Of Mice and Men.txt', 1073),\n",
       " ('kipling_jungle_book_txt.txt', 1698),\n",
       " ('london_white_txt.txt', 2507),\n",
       " ('stevenson_treasure_island_txt.txt', 2245),\n",
       " ('Stivenson_Fall-or-Dodge-in-Hell_RuLit_Me.txt', 7309),\n",
       " ('stoker_dracula_txt.txt', 3527),\n",
       " ('twain_tom_sawyer_txt.txt', 2862),\n",
       " ('walter_scott_ivanhoe_txt.txt', 4445),\n",
       " ('wells_invisible_man_txt.txt', 2316),\n",
       " ('wells_war_of_the_worlds_txt.txt', 2674),\n",
       " ('wilde_picture_of_dorian_gray_txt.txt', 2806)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# а так гапаксы будут считаться по леммам и, поскольку словарь лемм для каждого текста уже имеется в экземпляре каждого текста, \n",
    "# вычисляется гораздо быстрее\n",
    "[(txt.filename, len(txt.hapaxes())) for txt in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105136\n",
      "3758\n",
      "['wedged', 'wedlock', 'wee', 'weedy', 'weekly', 'weigh', 'weighing', 'weird', 'welcome', 'welcomed', 'well-cut', 'well-groomed', 'well-lit', 'well-nigh', 'well-nurtured', 'well-opened', 'well-remembered', 'wellington', 'westbury', 'western', 'westphail', 'westward', 'wheal', 'wheel', 'wheeled', 'wherever', 'whims', 'whine', 'whined', 'whirling', 'whishing', 'whisper', 'whispering', 'white-aproned', 'white-counterpaned', 'whiten', 'whiter', 'whither', 'whittington', 'wholesome', 'whoso', 'wicker-work', 'wicket', 'widow', 'wig', 'wight', 'wigmore', 'wigs', 'wilderness', 'wilful', 'wilhelm', 'will-o', 'willingly', 'willows', 'wilton', 'wimpole', 'win', 'winced', 'wincing', 'wind-swept', 'windfall', 'window-sill', 'windowsill', 'wine', 'wine-cellar', 'wines', 'winking', 'winter', 'wintry', 'wiry', 'wisdom', 'wishing', 'withdrawn', 'witnesses', 'wits', 'wives', 'woke', 'womanhood', 'wondered', 'wooded', 'wooden-leg', 'wooden-legged', 'worker', 'workmen', 'world-wide', 'worlds', 'worm-eaten', 'worms', 'worry', 'worthless', 'wounded', 'wrack', 'wreath', 'wreaths', 'wrenching', 'wretch', 'wriggled', 'writ', 'writers', 'writes', 'writings', 'x', 'ycuea', 'yell', 'yonder', 'zealand', 'zero', 'zero-point', 'zest', 'zigzag']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndoc = 3\n",
    "print(len(texts[ndoc].words(filtrate=False)))\n",
    "\n",
    "hp = texts[ndoc].hapaxes(words=True)\n",
    "print(len(hp))\n",
    "print(sorted(hp)[-110:len(hp)])\n",
    "'ycuea' in hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105136\n",
      "3758\n",
      "['wedged', 'wedlock', 'wee', 'weedy', 'weekly', 'weigh', 'weighing', 'weird', 'welcome', 'welcomed', 'well-cut', 'well-groomed', 'well-lit', 'well-nigh', 'well-nurtured', 'well-opened', 'well-remembered', 'wellington', 'westbury', 'western', 'westphail', 'westward', 'wheal', 'wheel', 'wheeled', 'wherever', 'whims', 'whine', 'whined', 'whirling', 'whishing', 'whisper', 'whispering', 'white-aproned', 'white-counterpaned', 'whiten', 'whiter', 'whither', 'whittington', 'wholesome', 'whoso', 'wicker-work', 'wicket', 'widow', 'wig', 'wight', 'wigmore', 'wigs', 'wilderness', 'wilful', 'wilhelm', 'will-o', 'willingly', 'willows', 'wilton', 'wimpole', 'win', 'winced', 'wincing', 'wind-swept', 'windfall', 'window-sill', 'windowsill', 'wine', 'wine-cellar', 'wines', 'winking', 'winter', 'wintry', 'wiry', 'wisdom', 'wishing', 'withdrawn', 'witnesses', 'wits', 'wives', 'woke', 'womanhood', 'wondered', 'wooded', 'wooden-leg', 'wooden-legged', 'worker', 'workmen', 'world-wide', 'worlds', 'worm-eaten', 'worms', 'worry', 'worthless', 'wounded', 'wrack', 'wreath', 'wreaths', 'wrenching', 'wretch', 'wriggled', 'writ', 'writers', 'writes', 'writings', 'x', 'ycuea', 'yell', 'yonder', 'zealand', 'zero', 'zero-point', 'zest', 'zigzag']\n"
     ]
    }
   ],
   "source": [
    "print(sum(corpus.cfs(ndoc).values()))\n",
    "ln = len(hapaxes[ndoc][1])\n",
    "print(ln)\n",
    "print(sorted(hapaxes[ndoc][1])[-110:ln])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3].vocab['conan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ycuea',\n",
       " 'aiaeeeneii',\n",
       " 'ia',\n",
       " 'eieae',\n",
       " 'aðoaea',\n",
       " 'walsall',\n",
       " 'manifested',\n",
       " 'mauritius',\n",
       " 'solely',\n",
       " 'survived']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapaxes[3][1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.cfs(3,'manifested')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# общекорпусная частота слова\n",
    "corpus.ccfs('manifested')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "842\n",
      "842\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(corpus.cfs(0,'have'))\n",
    "print(texts[0].words(filtrate=False).count('have'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(\n",
       "\tname='Austin Pride and Prejudice',\n",
       "\tencoding='utf-8',\n",
       "\tnsents=5950,\n",
       "\tnwords=122447,\n",
       "\tnlemmas=4950\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122447"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(corpus.cfs(0).values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2083"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.ccfs(\"am\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# частота слова для текста корпуса с номером 0\n",
    "corpus.cfs(0,'vicious')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.cfs(9,\"gregor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7905"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.ccfs(\"s\") # остатки притяжательных окончаний, которые токенизатор отделяет от основы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.dfs('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FreqDist({})\n"
     ]
    }
   ],
   "source": [
    "# тегов притяжательных окончаний нет, так как nltk.tag_pos умеет их определять только в виде \"'s\", а всю пунктуацию \n",
    "# в начале и в конце токена стрипает токенайзер (точнее, обертка вокруг него), поэтому в тексте остаются только токены вида \"s\"\n",
    "pos,_ = texts[10].postags(\"POS\")\n",
    "pprint(pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Gregor', 'NNP'), (\"'s\", 'POS')]\n",
      "[('Gregor', 'NNP'), ('s', 'NN')]\n",
      "[(\"Gregor's\", 'NN')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.pos_tag([\"Gregor\", \"'s\"]))\n",
    "#[('Gregor', 'NNP'), (\"'s\", 'POS')]\n",
    "\n",
    "print(nltk.pos_tag([\"Gregor\", \"s\"]))\n",
    "#[('Gregor', 'NNP'), ('s', 'NN')]\n",
    "\n",
    "# токены в которых притяжательное окончание присутствует tag_pos не умеет определять как NNP, то есть имена собственные\n",
    "print(nltk.pos_tag([\"Gregor's\"]))\n",
    "#[(\"Gregor's\", 'NN')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('troubled', 1),\n",
       " ('transformed', 1),\n",
       " ('vermin', 1),\n",
       " ('armour-like', 1),\n",
       " ('domed', 1),\n",
       " ('divided', 1),\n",
       " ('arches', 1),\n",
       " ('sections', 1),\n",
       " ('bedding', 1),\n",
       " ('cover', 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выводим слова с сортировкой по возрастанию частот\n",
    "corpus.cfs(9,sort=1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['something might happen',\n",
       " 'far from it',\n",
       " 'i m busy',\n",
       " 'bring a light',\n",
       " 'it was delightful',\n",
       " 'i just counted',\n",
       " 'night had fallen',\n",
       " 'something was impending',\n",
       " 'don t know',\n",
       " 'white fang paused']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[12].keywords(rating=('rake', dict(max_words=3))).topn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['And now was acknowledged the presence of the Red Death',\n",
       " 'Blood was its Avatar and its seal the redness and the horror of blood',\n",
       " 'It was in this apartment also that there stood against the western wall a gigantic clock of ebony',\n",
       " 'There were much of the beautiful much of the wanton much of the bizarre something of the terrible and not a little of that which might have excited disgust',\n",
       " 'To and fro in the seven chambers there stalked in fact a multitude of dreams',\n",
       " 'The figure was tall and gaunt and shrouded from head to foot in the habiliments of the grave',\n",
       " 'And then for a moment all is still and all is silent save the voice of the clock',\n",
       " 'But in spite of these things it was a gay and magnificent revel',\n",
       " 'It was in the blue room where stood the prince with a group of pale courtiers by his side',\n",
       " 'But these other apartments were densely crowded and in them beat feverishly the heart of life']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# много памяти для текстов имеющих больше 20 тыс. словоупотреблений\n",
    "print(texts[6].nwords) # рассказ Эдгара По 'Маска Красной Смерти'\n",
    "texts[6].summarize(10, scores=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndoc = 7\n",
    "words =  [set(sent.lemmas(uniq=True)) for sent in texts[ndoc].sents()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6506"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def similarity(s1, s2):\n",
    "        '''Мера сходства - коэффициент Сёренсена - \n",
    "        https://ru.wikipedia.org/wiki/Коэффициент_Сёренсена\n",
    "        отношение количества одинаковых слов в \n",
    "        предложениях к суммарной длине предложений.\n",
    "        ''' \n",
    "        if not len(s1) or not len(s2):\n",
    "            return 0.0\n",
    "        \n",
    "        return len(s1.intersection(s2))/(1.0 * (len(s1) + len(s2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsents = texts[ndoc].nsents    \n",
    "pairs = itertools.combinations(range(nsents), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11378564\n",
      "[(0, 1, 0.125), (0, 2, 0.15151515151515152), (0, 3, 0.125), (0, 4, 0.11538461538461539), (0, 5, 0.05555555555555555), (0, 6, 0.16666666666666666), (0, 7, 0.05263157894736842), (0, 8, 0.16), (0, 9, 0.08), (0, 10, 0.05)]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i, j in pairs:\n",
    "    sim = similarity(words[i], words[j])\n",
    "    if sim:\n",
    "        scores.append((i, j, sim)) \n",
    "    \n",
    "\n",
    "print(len(scores))\n",
    "print(scores[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
