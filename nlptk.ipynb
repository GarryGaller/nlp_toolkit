{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# минимально необходимые внешние модули\n",
    "#!pip install chardet\n",
    "#!pip install dawg\n",
    "#!pip install gensim\n",
    "#!pip install pattern\n",
    "#!pip install razdel\n",
    "#!pip install pymorphy2\n",
    "\n",
    "import sys, os\n",
    "# сменим рабочую директорию на ту, где расположен каталог с библиотекой nlptk\n",
    "os.chdir(r'D:\\INSTALL\\Python3\\PROJECTS\\REPOS\\nlp_toolkit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nlptk.mining.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим этот путь в sys.path, чтобы интерпретатор увидел нашу библиотеку\n",
    "sys.path.append(r'D:\\INSTALL\\Python3\\PROJECTS\\REPOS\\nlp_toolkit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pprint import pprint\n",
    "import nlptk\n",
    "from nlptk.mining.text import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentencizer': <function nlptk.misc.mixins.SentencizerMixin.sentencize_nltk(text, *args, lang='english', **kwargs)>,\n",
       " 'tokenizer': functools.partial(<function TokenizerMixin.toktok_tokenize at 0x12FCE390>, strip='!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'),\n",
       " 'tagger': <function nlptk.misc.mixins.TaggerMixin.tagger_nltk(tokens, *args, lang='eng', **kwargs)>,\n",
       " 'lemmatizer': functools.partial(<function LemmatizerMixin.lemmatize_nltk at 0x12FCE150>, pos=True, normalize_uppercase=<method 'capitalize' of 'str' objects>)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep = Prep()\n",
    "prep.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rules_clean = OrderedDict(\n",
    "        roman_numerals=(True,)\n",
    ")\n",
    "    \n",
    "rules_filter = OrderedDict(\n",
    "        by_tagpos=(True,{},{\"FW\",\"POS\"}), # фильтр по тегам частей речи - игнорировать иностранные слова и possessive ending parent's\n",
    "        punctuation=True, # по умолчанию\n",
    "        short=(True,3),   # по умолчанию\n",
    "        stopwords=True,   # по умолчанию\n",
    "        ifnotin_lexicon=True\n",
    "        #trailing_chars=True\n",
    ")\n",
    "\n",
    "clean = TextCleaner(rules_clean)\n",
    "filters = TokenFilter(rules_filter)   \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hyphenation', (True,)),\n",
       "             ('accent', (True,)),\n",
       "             ('tags', (True,)),\n",
       "             ('urls', (True,)),\n",
       "             ('numeric', (True,)),\n",
       "             ('nonletter_sequences', (True,)),\n",
       "             ('quotes', (True,)),\n",
       "             ('multiple_whitespaces', (True,)),\n",
       "             ('roman_numerals', (True,))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE⁄DT⁄The PICTURE⁄NN⁄Picture OF⁄IN⁄Of DORIAN⁄JJ⁄Dorian GRAY⁄NNP⁄Gray BY⁄IN⁄By OSCAR⁄NNP⁄Oscar WILDE⁄NNP⁄Wilde\n",
      "The⁄DT⁄The artist⁄NN⁄artist is⁄VBZ⁄be the⁄DT⁄the creator⁄NN⁄creator of⁄IN⁄of beautiful⁄JJ⁄beautiful things⁄NNS⁄thing\n",
      "PREFACE⁄NN⁄Preface\n"
     ]
    }
   ],
   "source": [
    "intake='''THE PICTURE OF DORIAN GRAY\n",
    "\n",
    "BY\n",
    "\n",
    "OSCAR WILDE. The artist is the creator of beautiful things. PREFACE'''\n",
    "text1 = Text(intake, prep, clean, filters, input='text', inplace=True)\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PICTURE',\n",
       " 'DORIAN',\n",
       " 'GRAY',\n",
       " 'OSCAR',\n",
       " 'WILDE',\n",
       " 'artist',\n",
       " 'creator',\n",
       " 'beautiful',\n",
       " 'things']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.words(lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedSentence(\n",
       " \t'THE⁄DT⁄The PICTURE⁄NN⁄Picture OF⁄IN⁄Of DORIAN⁄JJ⁄Dorian GRAY⁄NNP⁄Gray BY⁄IN⁄By OSCAR⁄NNP⁄Oscar WILDE⁄NNP⁄Wilde',\n",
       " \t n=0\n",
       " ), TaggedSentence(\n",
       " \t'The⁄DT⁄The artist⁄NN⁄artist is⁄VBZ⁄be the⁄DT⁄the creator⁄NN⁄creator of⁄IN⁄of beautiful⁄JJ⁄beautiful things⁄NNS⁄thing',\n",
       " \t n=1\n",
       " )]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('THE', 'DT', 'The'),\n",
       " ('PICTURE', 'NN', 'Picture'),\n",
       " ('OF', 'IN', 'Of'),\n",
       " ('DORIAN', 'JJ', 'Dorian'),\n",
       " ('GRAY', 'NNP', 'Gray'),\n",
       " ('BY', 'IN', 'By'),\n",
       " ('OSCAR', 'NNP', 'Oscar'),\n",
       " ('WILDE', 'NNP', 'Wilde')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.sents(0).untagging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The⁄DT⁄The Picture⁄NN⁄Picture of⁄IN⁄of Dorian⁄JJ⁄Dorian Gray⁄NNP⁄Gray By⁄IN⁄By Oscar⁄NNP⁄Oscar Wilde⁄NNP⁄Wilde\n"
     ]
    }
   ],
   "source": [
    "intake = 'The Picture of Dorian Gray By Oscar Wilde'\n",
    "text2 = Text(intake, prep, clean, filters, input='text', inplace=True)\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT', 'The'),\n",
       " ('Picture', 'NN', 'Picture'),\n",
       " ('of', 'IN', 'of'),\n",
       " ('Dorian', 'JJ', 'Dorian'),\n",
       " ('Gray', 'NNP', 'Gray'),\n",
       " ('By', 'IN', 'By'),\n",
       " ('Oscar', 'NNP', 'Oscar'),\n",
       " ('Wilde', 'NNP', 'Wilde')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2.sents(0).untagging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text(\n",
      "\tname='StringIO',\n",
      "\tnsents=1,\n",
      "\tnwords=8,\n",
      "\tnlemmas=8\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(repr(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method tfidf in module nlptk.mining.text:\n",
      "\n",
      "tfidf(n_doc, token=None, texts: List[List[str]] = [], sort=False) method of nlptk.mining.text.Corpus instance\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "source = os.path.abspath(os.path.join(MODULEDIR,r'corpus\\en'))\n",
    "corpus = Corpus(Path(source,\"*.txt\"), prep, clean, filters)\n",
    "corpus.verbose = True\n",
    "corpus.rewrite = True # перетегировать все тексты, даже если они сохранены \n",
    "#corpus.filtrate = True # применить фильтры при формировании общего вокабуляра; по умолчанию False\n",
    "print(help(corpus.tfidf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "for text in corpus:\n",
    "    # можно выводить объекты текстов text и что-то с ними делать, только нужно помнить, что они - генераторы предложений\n",
    "    # хотя параметр inplace=True заставит их отработать без цикла \n",
    "    texts.append(text)\n",
    "    for i,sent in enumerate(text):\n",
    "        pass # можно выводить предложения при обработке, но это замедлит работу \n",
    "        \n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus(\n",
      "\tnames=['Austin Pride and Prejudice.txt', 'bronte_jane_txt.txt',...],\n",
      "\tndocs=21,\n",
      "\tnwords=1927580,\n",
      "\tnlemmas=44991,\n",
      "\tnhapaxes=18047\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(repr(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedSentence(\n",
       "\t'THE⁄DT⁄The END⁄NN⁄End',\n",
       "\t n=6503\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Последнее предложение в корпусе, которое осталось в этой переменной после цикла обработки\n",
    "# сами предложения в объекте корпуса никак не сохраняются в целях экономии памяти. \n",
    "# Сохраняются только всевозможные частотные словари\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(\n",
       "\tname='wilde_picture_of_dorian_gray_txt.txt',\n",
       "\tnsents=13012,\n",
       "\tnwords=159588,\n",
       "\tnlemmas=5797\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# работаем с последним текстом, который интерпретатор сохранил в этой переменной\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THE⁄DT⁄The PICTURE⁄NN⁄Picture OF⁄IN⁄Of DORIAN⁄JJ⁄Dorian GRAY⁄NNP⁄Gray '\n",
      " 'BY⁄IN⁄By OSCAR⁄NNP⁄Oscar WILDE⁄NNP⁄Wilde THE⁄DT⁄The PREFACE⁄NNP⁄Preface '\n",
      " 'The⁄DT⁄The artist⁄NN⁄artist is⁄VBZ⁄be the⁄DT⁄the creator⁄NN⁄creator of⁄IN⁄of '\n",
      " 'beautiful⁄JJ⁄beautiful things⁄NNS⁄thing',\n",
      " 'To⁄TO⁄To reveal⁄VB⁄reveal art⁄NN⁄art and⁄CC⁄and conceal⁄VB⁄conceal '\n",
      " 'the⁄DT⁄the artist⁄NN⁄artist is⁄VBZ⁄be art⁄JJ⁄art s⁄NN⁄s aim⁄NN⁄aim',\n",
      " 'The⁄DT⁄The critic⁄NN⁄critic is⁄VBZ⁄be he⁄PRP⁄he who⁄WP⁄who can⁄MD⁄can '\n",
      " 'translate⁄VB⁄translate into⁄IN⁄into another⁄DT⁄another manner⁄NN⁄manner '\n",
      " 'or⁄CC⁄or a⁄DT⁄a new⁄JJ⁄new material⁄NN⁄material his⁄PRP$⁄his '\n",
      " 'impression⁄NN⁄impression of⁄IN⁄of beautiful⁄JJ⁄beautiful things⁄NNS⁄thing',\n",
      " 'The⁄DT⁄The highest⁄JJS⁄high as⁄IN⁄a the⁄DT⁄the lowest⁄JJS⁄low form⁄NN⁄form '\n",
      " 'of⁄IN⁄of criticism⁄NN⁄criticism is⁄VBZ⁄be a⁄DT⁄a mode⁄NN⁄mode of⁄IN⁄of '\n",
      " 'autobiography⁄NN⁄autobiography',\n",
      " 'Those⁄DT⁄Those who⁄WP⁄who find⁄VBP⁄find ugly⁄JJ⁄ugly meanings⁄NNS⁄meaning '\n",
      " 'in⁄IN⁄in beautiful⁄JJ⁄beautiful things⁄NNS⁄thing are⁄VBP⁄be '\n",
      " 'corrupt⁄JJ⁄corrupt without⁄IN⁄without being⁄VBG⁄be charming⁄VBG⁄charm',\n",
      " 'This⁄DT⁄This is⁄VBZ⁄be a⁄DT⁄a fault⁄NN⁄fault',\n",
      " 'Those⁄DT⁄Those who⁄WP⁄who find⁄VBP⁄find beautiful⁄JJ⁄beautiful '\n",
      " 'meanings⁄NNS⁄meaning in⁄IN⁄in beautiful⁄JJ⁄beautiful things⁄NNS⁄thing '\n",
      " 'are⁄VBP⁄be the⁄DT⁄the cultivated⁄JJ⁄cultivated',\n",
      " 'For⁄IN⁄For these⁄DT⁄these there⁄EX⁄there is⁄VBZ⁄be hope⁄NN⁄hope',\n",
      " 'They⁄PRP⁄They are⁄VBP⁄be the⁄DT⁄the elect⁄NN⁄elect to⁄TO⁄to whom⁄WP⁄whom '\n",
      " 'beautiful⁄JJ⁄beautiful things⁄NNS⁄thing mean⁄VBP⁄mean only⁄RB⁄only '\n",
      " 'Beauty⁄NNP⁄Beauty',\n",
      " 'There⁄EX⁄There is⁄VBZ⁄be no⁄DT⁄no such⁄JJ⁄such thing⁄NN⁄thing as⁄IN⁄a a⁄DT⁄a '\n",
      " 'moral⁄JJ⁄moral or⁄CC⁄or an⁄DT⁄an immoral⁄JJ⁄immoral book⁄NN⁄book']\n"
     ]
    }
   ],
   "source": [
    "# объект text при печати на консоль отображается как текст аналогичный сохраненному на диске тегированному тексту\n",
    "pprint(str(text).split(\"\\n\")[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70598"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем общее числу слов в тексте, но после фильтрации\n",
    "len(text.words(filtrate=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159610"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text.words(filtrate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1924217"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считаем сколько всего слов есть в корпусе по всем документам\n",
    "sum(corpus.ccfs().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedSentence(\n",
       "\t'THE⁄DT⁄The PICTURE⁄NN⁄Picture OF⁄IN⁄Of DORIAN⁄JJ⁄Dorian GRAY⁄NNP⁄Gray BY⁄IN⁄By OSCAR⁄NNP⁄Oscar WILDE⁄NNP⁄Wilde THE⁄DT⁄The PREFACE⁄NNP⁄Preface The⁄DT⁄The artist⁄NN⁄artist is⁄VBZ⁄be the⁄DT⁄the creator⁄NN⁄creator of⁄IN⁄of beautiful⁄JJ⁄beautiful things⁄NNS⁄thing',\n",
       "\t n=0\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# объект предложения в виде экземпляра класса TaggedSentence; n это порядковый номер предложения\n",
    "text.sents(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# легко догадаться, что это число слов в предложении\n",
    "text.sents(0).nwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedSentence(\n",
       " \t'Harry⁄NNP⁄Harry',\n",
       " \t n=234\n",
       " ), TaggedSentence(\n",
       " \t'Harry⁄NNP⁄Harry',\n",
       " \t n=281\n",
       " ), TaggedSentence(\n",
       " \t'Why⁄WRB⁄Why',\n",
       " \t n=371\n",
       " )]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# а так мы получаем все предложения из текста не длиннее одного слова\n",
    "text.sents(max_words=1)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedSentence(\n",
       " \t'This⁄DT⁄This is⁄VBZ⁄be a⁄DT⁄a fault⁄NN⁄fault',\n",
       " \t n=5\n",
       " ), TaggedSentence(\n",
       " \t'For⁄IN⁄For these⁄DT⁄these there⁄EX⁄there is⁄VBZ⁄be hope⁄NN⁄hope',\n",
       " \t n=7\n",
       " ), TaggedSentence(\n",
       " \t'That⁄DT⁄That is⁄VBZ⁄be all⁄DT⁄all',\n",
       " \t n=11\n",
       " )]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Давайте усложним условия: не менее трех, но не более пяти слов\n",
    "text.sents(min_words=3,max_words=5)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Token(token='the', idx=0, pos='DT', lemma='the', nsent=0),\n",
       " Token(token='picture', idx=1, pos='NN', lemma='picture', nsent=0),\n",
       " Token(token='of', idx=2, pos='IN', lemma='of', nsent=0),\n",
       " Token(token='dorian', idx=3, pos='JJ', lemma='dorian', nsent=0),\n",
       " Token(token='gray', idx=4, pos='NNP', lemma='gray', nsent=0),\n",
       " Token(token='by', idx=5, pos='IN', lemma='by', nsent=0),\n",
       " Token(token='oscar', idx=6, pos='NNP', lemma='oscar', nsent=0),\n",
       " Token(token='wilde', idx=7, pos='NNP', lemma='wilde', nsent=0),\n",
       " Token(token='the', idx=8, pos='DT', lemma='the', nsent=0),\n",
       " Token(token='preface', idx=9, pos='NNP', lemma='preface', nsent=0),\n",
       " Token(token='the', idx=10, pos='DT', lemma='the', nsent=0),\n",
       " Token(token='artist', idx=11, pos='NN', lemma='artist', nsent=0),\n",
       " Token(token='is', idx=12, pos='VBZ', lemma='be', nsent=0),\n",
       " Token(token='the', idx=13, pos='DT', lemma='the', nsent=0),\n",
       " Token(token='creator', idx=14, pos='NN', lemma='creator', nsent=0),\n",
       " Token(token='of', idx=15, pos='IN', lemma='of', nsent=0),\n",
       " Token(token='beautiful', idx=16, pos='JJ', lemma='beautiful', nsent=0),\n",
       " Token(token='things', idx=17, pos='NNS', lemma='thing', nsent=0))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# А если мы хотим получить предложение в более информативном виде? Класс Token к вашим услугам.\n",
    "# Метод tokens трансформирует предложение в список экземпляров этого класса.\n",
    "text.sents(0).tokens(lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Token(token='picture', idx=1, pos='NN', lemma='picture', nsent=0),\n",
       " Token(token='dorian', idx=3, pos='JJ', lemma='dorian', nsent=0),\n",
       " Token(token='gray', idx=4, pos='NNP', lemma='gray', nsent=0),\n",
       " Token(token='oscar', idx=6, pos='NNP', lemma='oscar', nsent=0),\n",
       " Token(token='wilde', idx=7, pos='NNP', lemma='wilde', nsent=0),\n",
       " Token(token='preface', idx=9, pos='NNP', lemma='preface', nsent=0),\n",
       " Token(token='artist', idx=11, pos='NN', lemma='artist', nsent=0),\n",
       " Token(token='creator', idx=14, pos='NN', lemma='creator', nsent=0),\n",
       " Token(token='beautiful', idx=16, pos='JJ', lemma='beautiful', nsent=0),\n",
       " Token(token='things', idx=17, pos='NNS', lemma='thing', nsent=0))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Попробуем включить фильтрацию (это те самые rules_filter, которые мы передавали в объект Corpus, \n",
    "# но которые по умолчанию отключены параметром corpus.filtrate=False, \n",
    "# чтобы в объекте корпуса сохранялась статистика по всем словам\n",
    "text.sents(0).tokens(lower=True,filtrate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the',\n",
       " 'picture',\n",
       " 'of',\n",
       " 'dorian',\n",
       " 'gray',\n",
       " 'by',\n",
       " 'oscar',\n",
       " 'wilde',\n",
       " 'the',\n",
       " 'preface',\n",
       " 'the',\n",
       " 'artist',\n",
       " 'is',\n",
       " 'the',\n",
       " 'creator',\n",
       " 'of',\n",
       " 'beautiful',\n",
       " 'things')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# все слова предложения с указанным номером\n",
    "text.sents(0).words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the',\n",
       " 'picture',\n",
       " 'of',\n",
       " 'dorian',\n",
       " 'gray',\n",
       " 'by',\n",
       " 'oscar',\n",
       " 'wilde',\n",
       " 'the',\n",
       " 'preface',\n",
       " 'the',\n",
       " 'artist',\n",
       " 'be',\n",
       " 'the',\n",
       " 'creator',\n",
       " 'of',\n",
       " 'beautiful',\n",
       " 'thing')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# все леммы предложения с указанным номером\n",
    "text.sents(0).lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('THE', 'DT', 'The'),\n",
       " ('PICTURE', 'NN', 'Picture'),\n",
       " ('OF', 'IN', 'Of'),\n",
       " ('DORIAN', 'JJ', 'Dorian'),\n",
       " ('GRAY', 'NNP', 'Gray'),\n",
       " ('BY', 'IN', 'By'),\n",
       " ('OSCAR', 'NNP', 'Oscar'),\n",
       " ('WILDE', 'NNP', 'Wilde'),\n",
       " ('THE', 'DT', 'The'),\n",
       " ('PREFACE', 'NNP', 'Preface'),\n",
       " ('The', 'DT', 'The'),\n",
       " ('artist', 'NN', 'artist'),\n",
       " ('is', 'VBZ', 'be'),\n",
       " ('the', 'DT', 'the'),\n",
       " ('creator', 'NN', 'creator'),\n",
       " ('of', 'IN', 'of'),\n",
       " ('beautiful', 'JJ', 'beautiful'),\n",
       " ('things', 'NNS', 'thing')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# разтегированное представаление предложения\n",
    "text.sents(0).untagging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('picture', 'artist', 'creator', 'things')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# слова предложения отфильтрованные по частям речи - сущ. (в ед. и мн. числе\n",
    "text.sents(0).words(pos={\"NN\",\"NNS\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('picture', 'artist', 'creator', 'thing')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# леммы предложения отфильтованные по частям речи - сущ. (в ед. и мн. числе)\n",
    "text.sents(0).lemmas(pos={\"NN\",\"NNS\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('picture', 'gray', 'oscar', 'wilde', 'preface', 'artist', 'creator', 'thing')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# все леммы чей postag начинается на N, то есть любые существительные\n",
    "text.sents(0).lemmas(pos=\"N\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dorian', 'beautiful')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.sents(0).lemmas(pos=\"JJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE PICTURE OF DORIAN GRAY BY OSCAR WILDE THE PREFACE The artist is the creator of beautiful things'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Предложение как есть, но уже без пунктуации, так как она была удалена на этапе очистки текста фильтрами TextCleaner\n",
    "text.sents(0).raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'picture',\n",
       " 'of',\n",
       " 'dorian',\n",
       " 'gray',\n",
       " 'by',\n",
       " 'oscar',\n",
       " 'wilde',\n",
       " 'the',\n",
       " 'preface']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.words(filtrate=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'be': 7086, 'have': 3158, 'say': 776, 'do': 740, 'go': 590, 'know': 518, 'come': 460, 'look': 420, 'make': 410, 'think': 390, ...})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Можно получить частотные словари по любой части речи\n",
    "verbs,cond = text.postags(\"VERB\")[:10]\n",
    "verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'dorian': 582, 'good': 276, 'own': 256, 'great': 164, 'little': 164, 'young': 156, 'other': 144, 'more': 130, 'such': 130, 'old': 124, ...})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjectives,cond = text.postags(\"ADJ\")[:10]\n",
    "adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'s': 4})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possessive,cond = text.postags(\"POS\")[:10]\n",
    "possessive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('picture', 'dorian', 'gray')\n",
      "('picture', 'dorian', 'oscar')\n",
      "('picture', 'dorian', 'wilde')\n",
      "('picture', 'gray', 'oscar')\n",
      "('picture', 'gray', 'wilde')\n",
      "('picture', 'oscar', 'wilde')\n",
      "('dorian', 'gray', 'oscar')\n",
      "('dorian', 'gray', 'wilde')\n",
      "('dorian', 'gray', 'preface')\n",
      "('dorian', 'oscar', 'wilde')\n",
      "('dorian', 'oscar', 'preface')\n",
      "('dorian', 'wilde', 'preface')\n"
     ]
    }
   ],
   "source": [
    "# генерация skipgram из текста (имплементация из nltk)\n",
    "for n,s in enumerate(text.skipgrams(3,2)):\n",
    "    print(s)\n",
    "    if n > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('picture', 'dorian', 'gray')\n",
      "('dorian', 'gray', 'oscar')\n",
      "('gray', 'oscar', 'wilde')\n",
      "('oscar', 'wilde', 'preface')\n",
      "('wilde', 'preface', 'artist')\n",
      "('preface', 'artist', 'creator')\n",
      "('artist', 'creator', 'beautiful')\n",
      "('creator', 'beautiful', 'thing')\n",
      "('beautiful', 'thing', 'reveal')\n",
      "('thing', 'reveal', 'art')\n",
      "('reveal', 'art', 'conceal')\n",
      "('art', 'conceal', 'artist')\n"
     ]
    }
   ],
   "source": [
    "# генерация ngram из текста (имплементация из nltk)\n",
    "for n,s in enumerate(text.ngrams(3)):\n",
    "    print(s)\n",
    "    if n > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 401),\n",
       " (1, 557),\n",
       " (2, 375),\n",
       " (3, 486),\n",
       " (4, 1474),\n",
       " (5, 24),\n",
       " (6, 0),\n",
       " (7, 2),\n",
       " (8, 234),\n",
       " (9, 51),\n",
       " (10, 390),\n",
       " (11, 430),\n",
       " (12, 70),\n",
       " (13, 341),\n",
       " (14, 1286),\n",
       " (15, 567),\n",
       " (16, 356),\n",
       " (17, 1451),\n",
       " (18, 531),\n",
       " (19, 166),\n",
       " (20, 262)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[(n,corpus.cfs(n).get('said',0)) for n in range(corpus.ndocs)]\n",
    "[(n,corpus.cfs(n,'said')) for n in range(corpus.ndocs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.00016092431058203172),\n",
       " (1, 0.0001464246459680258),\n",
       " (2, 0.00015695153735030426),\n",
       " (3, 0.00022664684706076194),\n",
       " (4, 0.00046786045503820624),\n",
       " (5, 0.0005016983462152395),\n",
       " (6, 0),\n",
       " (7, 4.6050178545948135e-05),\n",
       " (8, 0.0002369290143741486),\n",
       " (9, 0.0001130582203935224),\n",
       " (10, 0.0006388076686500319),\n",
       " (11, 0.00041020179084672563),\n",
       " (12, 4.736252242213623e-05),\n",
       " (13, 0.0002434938236414988),\n",
       " (14, 0.00019914731966168658),\n",
       " (15, 0.00017248295113736134),\n",
       " (16, 0.0002453879949185229),\n",
       " (17, 0.0003662777417844791),\n",
       " (18, 0.000529948190193066),\n",
       " (19, 0.00013452648869904027),\n",
       " (20, 0.00016156296068542102)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(n,corpus.tfidf(n,'said')) for n in range(corpus.ndocs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " [('holmes', 0.013378570292080937),\n",
       "  ('sherlock', 0.002169412950320131),\n",
       "  ('watson', 0.0014991888798649405),\n",
       "  ('lestrade', 0.0011004018854958346),\n",
       "  ('rucastle', 0.0011004018854958346),\n",
       "  ('mccarthy', 0.001071443941140681),\n",
       "  ('simon', 0.0008946032784825284)],\n",
       " 'doyle_the_adventures.txt')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# набор наиболее весомых по метрике TFIDF слов в каждом тексте\n",
    "res = [(n,corpus.tfidf(n,sort=-1)[0:7],\n",
    "        os.path.basename(path)\n",
    " ) \n",
    "     for n,path in enumerate(corpus.filenames())\n",
    "]\n",
    "res[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отображение слов из 3-го текста в порядковый номер в словаре tdidf\n",
    "ordered_by_tfidf = {word:n for n,(word,_) in enumerate(corpus.tfidf(3,sort=-1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordered_by_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# как видим метрика хотя и дает наибольшие веса словам важным для контекста произведения - именам главных персонажей,\n",
    "# но очень быстро скатывается до уровня частоупотребляемых вместе с этими словами сокращений типа mr.\n",
    "# чья документтная частота очень и очень высока \n",
    "# (но их можно удалять фильтрацией, которую мы на уровне корпуса не включали, поэтому все стоп-слова и остались на месте)\n",
    "corpus.dfs('mr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "ordered_by_tfidf['mr'] # на  8 месте если упоядочить слова по TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_by_tfidf['said']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.cfs(3,'mr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.dfs('holmes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.cfs(3,'holmes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00020712636290766274"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.tfidf(6,\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "486"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.cfs(3,'said')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.dfs('said')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00022664684706076194"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.tfidf(3,'said')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prospero', 0.007551523202290425),\n",
       " ('courtiers', 0.0038881773578561016),\n",
       " ('waltzers', 0.0037757616011452125),\n",
       " ('mummer', 0.0037757616011452125),\n",
       " ('prince', 0.0036805490437174567),\n",
       " ('ebony', 0.0029662764061375003),\n",
       " ('musicians', 0.002413282532933419),\n",
       " ('revellers', 0.002413282532933419),\n",
       " ('suite', 0.002071538600240377),\n",
       " ('sable', 0.0020565044356389405)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.tfidf(6,sort=-1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method tfidf in module nlptk.mining.text:\n",
      "\n",
      "tfidf(n_doc, texts: List[List[str]] = None, token=None, sort=False) method of nlptk.mining.text.Corpus instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(corpus.tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312\n",
      "185598\n",
      "1\n",
      "0.0016810525975495426\n",
      "3.044522437723423\n",
      "0.005118002352232825\n"
     ]
    }
   ],
   "source": [
    "print(corpus.cfs(1,'rochester'))\n",
    "print(sum(corpus.cfs(1).values()))\n",
    "print(corpus.dfs('rochester'))\n",
    "print(corpus.tf(1,'rochester'))\n",
    "print(corpus.idf('rochester'))\n",
    "print(corpus.tfidf(1,token='rochester'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--cfc--\n",
      "[('the', 4320),\n",
      " ('to', 4127),\n",
      " ('of', 3596),\n",
      " ('and', 3529),\n",
      " ('her', 2216),\n",
      " ('i', 2046),\n",
      " ('a', 1945),\n",
      " ('in', 1861),\n",
      " ('was', 1843),\n",
      " ('she', 1703)]\n",
      "--ccfc--\n",
      "[('the', 104005),\n",
      " ('and', 64431),\n",
      " ('of', 53145),\n",
      " ('to', 51249),\n",
      " ('a', 42386),\n",
      " ('i', 34454),\n",
      " ('in', 29525),\n",
      " ('he', 28953),\n",
      " ('was', 26894),\n",
      " ('it', 24706)]\n",
      "--dfc--\n",
      "[('over', 21),\n",
      " ('once', 21),\n",
      " ('moment', 21),\n",
      " ('a', 21),\n",
      " ('minutes', 21),\n",
      " ('by', 21),\n",
      " ('four', 21),\n",
      " ('not', 21),\n",
      " ('from', 21),\n",
      " ('loud', 21)]\n",
      "--tfidf--\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input(\"--cfc--\")\n",
    "pprint(corpus.cfs(0,sort=-1)[:10])\n",
    "input(\"--ccfc--\")\n",
    "pprint(corpus.ccfs(sort=-1)[:10])\n",
    "input(\"--dfc--\")\n",
    "pprint(corpus.dfs(sort=-1)[:10])\n",
    "input(\"--tfidf--\")\n",
    "\n",
    "#for n in range(corpus.ndocs):\n",
    "#    pprint(corpus.tfidf(n,sort=-1)[:10]) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18047"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# общее число слов-одиночек\n",
    "all_hapaxes = corpus.hapaxes()\n",
    "len(all_hapaxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a-bleeding',\n",
       " 'a-blowing',\n",
       " 'a-buttin',\n",
       " 'a-callin',\n",
       " 'a-chaffin',\n",
       " 'a-changing',\n",
       " 'a-crossin',\n",
       " 'a-doin',\n",
       " 'a-doing',\n",
       " 'a-done']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# н-да, вот что значит не включать фильтрацию на корпусе ...\n",
    "sorted(all_hapaxes)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uniting',\n",
       " 'city',\n",
       " 'pollution',\n",
       " 'liberties',\n",
       " 'sportive',\n",
       " 'arrear',\n",
       " 'heretofore',\n",
       " 'retain',\n",
       " 'bath',\n",
       " 'cheap']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем слова-одиночки для каждого текста в корпусе\n",
    "hapaxes = [(path, corpus.hapaxes(n)) for n,path in enumerate(corpus.filenames())]\n",
    "hapaxes[0][1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Austin Pride and Prejudice.txt', 2794),\n",
       " ('bronte_jane_txt.txt', 7459),\n",
       " ('bronte_wuthering_txt.txt', 4381),\n",
       " ('doyle_the_adventures.txt', 3814),\n",
       " ('dreiser_sister.txt', 4629),\n",
       " ('Edgar Allan Poe The Cask of Amontillado.txt', 547),\n",
       " ('Edgar Allan Poe The Masque of the Red Death.txt', 585),\n",
       " ('Edgar Allan Poe The Tell-Tale Heart.txt', 384),\n",
       " ('fitzgerald_great_gatsby_txt.txt', 3594),\n",
       " ('Franz Kafka - Metamorphosis.txt', 1308),\n",
       " ('John Steinbeck - Of Mice and Men.txt', 1435),\n",
       " ('kipling_jungle_book_txt.txt', 2238),\n",
       " ('london_white_txt.txt', 3232),\n",
       " ('stevenson_treasure_island_txt.txt', 3024),\n",
       " ('Stivenson_Fall-or-Dodge-in-Hell_RuLit_Me.txt', 10277),\n",
       " ('stoker_dracula_txt.txt', 4515),\n",
       " ('twain_tom_sawyer_txt.txt', 3746),\n",
       " ('walter_scott_ivanhoe_txt.txt', 5859),\n",
       " ('wells_invisible_man_txt.txt', 2994),\n",
       " ('wells_war_of_the_worlds_txt.txt', 3384),\n",
       " ('wilde_picture_of_dorian_gray_txt.txt', 3585)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сколько у нас хапаксов на каждый текст\n",
    "[(h[0],len(h[1])) for h in hapaxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9454"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# общекорпусная частота слова\n",
    "corpus.ccfs('said')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2083"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.ccfs(\"am\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# частота слова для корпуса с номером 0\n",
    "corpus.cfs(0,'vicious')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.cfs(9,\"gregor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7905"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.ccfs(\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.dfs('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FreqDist({})\n"
     ]
    }
   ],
   "source": [
    "pos,_ = texts[10].postags(\"POS\")\n",
    "pprint(pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('troubled', 1),\n",
       " ('transformed', 1),\n",
       " ('vermin', 1),\n",
       " ('armour-like', 1),\n",
       " ('domed', 1),\n",
       " ('divided', 1),\n",
       " ('arches', 1),\n",
       " ('sections', 1),\n",
       " ('bedding', 1),\n",
       " ('cover', 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.cfs(9,sort=1)[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
